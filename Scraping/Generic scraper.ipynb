{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper générique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de cette fonction est de récupérer plusieurs informations sur tous les articles disponibles sur internet quelque soit le site. <br>\n",
    "Pour chaque article, la fonction essaie de récupérer:\n",
    "    - \"art_content\": le contenu de l'article\n",
    "    - \"art_content_html\": le contenu de l'article avec les balises html\n",
    "    - \"art_published_datetime\": la date de publication ou de modification de l'article et sinon le jour d'utilisation du scraper\n",
    "    - \"art_lang\": la langue de l'article\n",
    "    - \"art_title\": le titre de l'article\n",
    "    - \"art_url\": l'url de l'article\n",
    "    - \"src_name\": le nom du site internet sur lequel est l'article\n",
    "    - \"src_type\": la façon de récupérer l'article (xpath_source pour tous les articles)\n",
    "    - \"src_url\": l'url de base du site internet\n",
    "    - \"art_img\": l'image associée à l'article\n",
    "    - \"art_auth\": le ou les auteurs de l'article\n",
    "    - \"art_tag\": les tags associés à l'article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque information la fonction teste si des balises sont présentes dans le code source de l'article. Ces balises sont celles qui contiennent l'information voulue dans la plupart des codes des articles que l'on a rencontré pendant le projet. Enfin si aucune des balises recherchées ne sont disponibles dans le code source, la fonction renvoie np.nan (Not A Number) qui est équivalent à un None.\n",
    "Pour ce qui est du contenu, on a essayé différentes façons de le récupérer, elles seront expliqués plus loin dans le notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction complète du scraper générique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_generic(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Getting content\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li']\n",
    "    if soup.find('article') is not None:\n",
    "        content_html = soup.find('article')\n",
    "        if soup.find('article').find_all(list_balises, recursive = False):\n",
    "            content = soup.find('article').find_all(list_balises, string = True)\n",
    "            content = ' '.join(tag.text for tag in content)\n",
    "        else:\n",
    "            list_p = soup.find('article').find_all('div', recursive = 'False')\n",
    "            print([p.parent.name for p in list_p])\n",
    "            list_parent_p = [p.parent for p in list_p]\n",
    "            print(list_parent_p)\n",
    "            if len(set(list_parent_p)) == 1:\n",
    "                content_html = list_parent_p[0]\n",
    "                print(content_html)\n",
    "                content = ' '.join(\n",
    "                    tag.text for tag in content_html.children if tag.name in list_balises)\n",
    "            else:\n",
    "                content_html = soup.find('article')\n",
    "                content = [el.get_text() for el in list_parent_p]\n",
    "                content = ' '.join(content)\n",
    "    else:\n",
    "        list_div = list()\n",
    "        for el in soup.find_all('div'):\n",
    "            if el.find_all('p', recursive = False):\n",
    "                list_div.append(el)\n",
    "        index_max = np.argmax([len(block.find_all('p')) for block in list_div])\n",
    "        content_html = list_div[index_max]\n",
    "        content = ' '.join(\n",
    "            tag.text for tag in content_html.children if tag.name in list_balises)\n",
    "    content = content.replace('\\xa0', '').replace('\\t', '').replace('\\r', '').strip()\n",
    "    content_html_str = str(content_html)\n",
    "    \n",
    "    # Getting date of publication\n",
    "    if soup.find(\"meta\", {\"property\"\n",
    "                          \"article:modified_time\"}) is not None:\n",
    "        date = soup.find(\"meta\", {\"property\"\n",
    "                                  \"article:modified_time\"})[\"content\"]\n",
    "    elif soup.find(\"meta\", {\"property\": \"article:published_time\"}) is not None:\n",
    "        date = soup.find(\"meta\", {\"property\": \"article:published_time\"})[\n",
    "            \"content\"]\n",
    "    else:\n",
    "        date = datetime.date.today()\n",
    "\n",
    "    # Getting language\n",
    "    art_lang = TextBlob(content).detect_language()\n",
    "\n",
    "    # Getting title\n",
    "    if soup.find(\"meta\", {\"property\": \"og:title\"}) is not None:\n",
    "        title = soup.find(\"meta\", {\"property\": \"og:title\"})[\"content\"]\n",
    "    elif soup.find(\"title\") is not None:\n",
    "        title = soup.find(\"title\").get_text()\n",
    "    else:\n",
    "        title = np.nan\n",
    "\n",
    "    # Getting article url\n",
    "    if soup.find(\"meta\", {\"property\": \"og:url\"}) is not None:\n",
    "        art_url = soup.find(\"meta\", {\"property\": \"og:url\"})[\"content\"]\n",
    "    elif soup.find(\"link\", rel=\"canonical\"):\n",
    "        art_url = soup.find(\"link\", rel=\"canonical\")[\"href\"]\n",
    "    else:\n",
    "        art_url = url\n",
    "\n",
    "    # Getting source url\n",
    "    src_url = BigScraper.get_base_url(art_url)\n",
    "\n",
    "    # Getting source name\n",
    "    if soup.find(\"meta\", {\"property\": \"og:site_name\"}) is not None:\n",
    "        src_name = soup.find(\"meta\", {\"property\": \"og:site_name\"})[\"content\"]\n",
    "    else:\n",
    "        src_name = art_url.split(r\"//\")\n",
    "        if \"http\" in src_name[0]:\n",
    "            src_name = src_name[1]\n",
    "        else:\n",
    "            src_name = src_name[0]\n",
    "        src_name = src_name.split(r\"/\")[0]\n",
    "        for i in [\"fr.\", \"www.\", \"www2.\", \".org\", \".fr\", \".eu\", \".net\", \".com\"]:\n",
    "            src_name = src_name.replace(i, \"\")\n",
    "\n",
    "    # Source type\n",
    "    src_type = \"xpath_source\"\n",
    "\n",
    "    # Getting image\n",
    "    if soup.find(\"meta\", {\"property\": \"og:image\"}) is not None:\n",
    "        art_img = soup.find(\"meta\", {\"property\": \"og:image\"})[\"content\"]\n",
    "    else:\n",
    "        art_img = np.nan\n",
    "\n",
    "    # Getting author\n",
    "    if soup.find(\"meta\", {\"name\": \"author\"}) is not None:\n",
    "        art_auth = soup.find(\"meta\", {\"name\": \"author\"})[\"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"name\": \"twitter:data1\"}) is not None:\n",
    "        art_auth = soup.find(\"meta\", {'name': \"twitter:data1\"})[\n",
    "            \"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"property\": \"sage:author\"}) is not None:\n",
    "        art_auth = soup.find(\"meta\", {\"property\": \"sage:author\"})[\n",
    "            \"content\"].split(\",\")\n",
    "    else:\n",
    "        art_auth = np.nan\n",
    "\n",
    "    # Getting tags\n",
    "    if soup.find(\"meta\", {\"name\": \"keywords\"}) is not None:\n",
    "        art_tag = soup.find(\"meta\", {\"name\": \"keywords\"})[\"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"sage\": \"sageTags\"}) is not None:\n",
    "        art_tag = soup.find(\"meta\", {\"sage\": \"sageTags\"})[\"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"property\": \"article:tag\"}) is not None:\n",
    "        art_tag = soup.find(\"meta\", {\"property\": \"article:tag\"})[\n",
    "            \"content\"].split(\",\")\n",
    "    else:\n",
    "        art_tag = np.nan\n",
    "\n",
    "    return [content, content_html_str, date, art_lang, title, art_url, src_url, src_name, src_type, art_img, art_auth, art_tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Différentes façon de récupérer le contenu des articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1er cas: Contenu dans la balise article***<br>\n",
    "La fonction *get_content_article* va chercher toutes les balises qui peuvent contenir du texte dans la balise \"article\" même si ce contenu est dans différentes balises \"div\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_article(soup):\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li']\n",
    "    try:\n",
    "        content_html = soup.find(\"article\")\n",
    "        try:\n",
    "            content = \"\\n\".join(tag.text for tag in soup.find(\"article\").find_all(list_balises))\n",
    "        except:\n",
    "            content = np.nan\n",
    "    except:\n",
    "        content_html = np.nan\n",
    "        content = np.nan\n",
    "    return content, content_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2ème cas: Contenu dans des balises div qui sont dans une balise article***<br>\n",
    "La fonction *get_content_div_in_article* récupère toutes les balises qui peuvent contenir du texte dans une balise \"div\" située dans la balise \"article\". Si il y a plusieurs balises \"div\" dans la balise \"article\", la fonction sélectionne celle qui contient le plus de balises qui contiennent du texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_div_in_article(soup):\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li']\n",
    "    for tag in soup.find(\"article\").find_all(\"div\"):\n",
    "        if type(tag) == bs4.element.Tag:\n",
    "            children_names = [element.name for element in tag.contents if element.name is not None]\n",
    "            content_html = list()\n",
    "            if len(set(children_names) & set(list_balises)) != 0:\n",
    "                content_html.append(tag)\n",
    "    for div in content_html:\n",
    "        content = \"\\n\".join(tag.text for tag in div.children if tag.name in list_balises)\n",
    "    content = content.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\")\n",
    "    return content, content_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3ème cas: Contenu dans une seule balise div parmis d'autres***<br>\n",
    "La fonction *get_content_max_div* cherche la balise \"div\" qui contient le contenu de l'article. Pour cela, elle parcourt toutes les balises \"div\" et vérifie s'il y a une balise qui contient du texte dans ses enfants directs, si c'est le cas, la balise \"div\" et tout son contenu sont ajoutés à une liste. Enfin pour sélectionner une seule balise \"div\", comme précédemment, la fonction sélectionne celle qui contient le plus de balises faites pour le texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_max_div(soup):\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li', 'span']\n",
    "    list_div = list()\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        if div.find_all(list_balises, recursive = False):\n",
    "            list_div.append(div)\n",
    "    idx_max = np.argmax([len(div.find_all(list_balises)) for div in list_div])\n",
    "    content_html = list_div[idx_max]\n",
    "    content = \"\\n\".join(tag.text for tag in content_html.children if tag.name in list_balises).strip().replace(\"\\xa0\", \"\")\n",
    "    return content, content_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***4ème cas: Contenu dans plusieurs balises div (on prend la balise qui comprend le plus de balises div contenant du texte)***<br>\n",
    "La fonction *get_content_all_div* cherche toutes les balises \"div\" qui ont une balise qui contient du texte parmis les balises enfants. Ensuite, pour sélectionner une seule balise \"div\", la fonction construit une liste avec toutes les balises parents des balises \"div\" sélectionnées puis sélectionne la balise parent la plus présente dans la liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_all_div(soup):\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li', 'span']\n",
    "    list_div = [div for div in soup.find_all(\"div\") if div.find_all(list_balises, recursive = False)] # all div with one element of the list_balises as descendant\n",
    "    list_parents = [div.parent for div in list_div] # parent tag for each div\n",
    "    content_html = max(set(list_parents), key = list_parents.count) # most parent tag in list_parents\n",
    "    content = \"\\n\".join(tag.text for tag in div if tag in list_balises for div in content_html.children if div in list_div)\n",
    "    return content, content_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***5ème cas: Contenu recherché à partir des balises contenues***<br>\n",
    "La fonction *get_content_from_tag* recherche toutes les balises dans le code source qui contiennent le texte. Puis, pour chacune de ces balises, cherche sa balise parent et sélectionne la balise parent la plus présente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_from_tag(soup):\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li', 'span']\n",
    "    list_parents = [tag.parent for tag in soup.find_all(list_balises)]\n",
    "    content_html = max(set(list_parents), key = list_parents.count)\n",
    "    content = \"\\n\".join(tag.text for tag in content_html.contents if tag.name in list_balises)\n",
    "    return content, content_html       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test des différentes fonctions de scraping générique pour le contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url = [\"https://www.fnccr.asso.fr/article/big-data-territorial-publication-de-letude-de-la-fnccr/\",\n",
    "      \"https://www.theinnovation.eu/comment-tuer-linnovation-avec-lanalyse-financiere/45\",\n",
    "      \"https://www.lemondeinformatique.fr/actualites/lire-les-salaries-et-les-dirigeants-percoivent-differement-la-transformation-digitale-81352.html\",\n",
    "      \"https://www.cnil.fr/fr/les-collectivites-territoriales-et-lopen-data-concilier-ouverture-des-donnees-et-protection-des\",\n",
    "      \"https://www.inserm.fr/actualites-et-evenements/actualites/ondes-electromagnetiques-faut-il-craindre-5g\",\n",
    "      \"https://www.parlonsrh.com/raisons-utiliser-lintelligence-artificielle-dans-gestion-gpec/\",\n",
    "      \"https://www.myrhline.com/actualite-rh/de-la-gpec-et-au-workforce-planning-les-5-evolutions-a-connaitre.html\",\n",
    "      \"https://grh-multi.net/fr/2016/05/compte-rendu-de-levenement-big-data-gpec/\",\n",
    "      \"https://changethework.com/gestion-paie-innovations/\",\n",
    "      \"https://changethework.com/chatbot-rh-recrutement/\",\n",
    "      \"http://sabbar.fr/management/le-management-strategique-et-le-management-operationnel/#:~:text=Le%20management%20op%C3%A9rationnel%20correspond%20aux,pour%20atteindre%20les%20objectifs%20fix%C3%A9s.\",\n",
    "      \"https://blockchainfrance.net/decouvrir-la-blockchain/c-est-quoi-la-blockchain/\",\n",
    "      \"https://citoyen-ne-s-de-marseille.fr/cest-quoi-les-autorisations-de-programmes/\",\n",
    "      \"https://hellofuture.orange.com/fr/mot-de-linnovation-brain-computer-interface/\",\n",
    "      \"https://omicron-formation.fr/3-gestion-et-organisation-de-la-cybersecurite/\",\n",
    "      \"https://www.data.gouv.fr/fr/datasets/les-elus-municipaux/\",\n",
    "      \"https://www.data.gouv.fr/fr/datasets/repertoire-national-des-elus-1/\",\n",
    "      \"https://www.digitalrecruiters.com/blog/ia-et-machine-learning-comment-optimiser-en-profondeur-les-processus-rh.html\",\n",
    "      \"https://www.erudit.org/fr/revues/ipme/2014-v27-n2-ipme01485/1026072ar/\",\n",
    "      \"https://www.lebigdata.fr/base-de-donnees\",\n",
    "      \"https://www.linternaute.fr/dictionnaire/fr/definition/agglomeration/\",\n",
    "      \"https://www.linternaute.fr/dictionnaire/fr/definition/software/\",\n",
    "      \"https://www.riskinsight-wavestone.com/2019/08/detecter-incidents-machine-learning/\",\n",
    "      \"https://www.sap.com/france/products/erp-financial-management/grc.html\",\n",
    "      \"https://www.cadre-dirigeant-magazine.com/manager/la-recherche-operationnelle-un-formidable-outil-daide-a-la-decision/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content = pd.DataFrame(columns = [\"article\", \"div_in_article\", \"one_div\", \"all_div\", \"from_tag\"])\n",
    "df_content_html = pd.DataFrame(columns = [\"article\", \"div_in_article\", \"one_div\", \"all_div\", \"from_tag\"])\n",
    "for url in Url:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    list_func = [get_content_article, get_content_div_in_article, get_content_max_div, get_content_all_div, get_content_from_tag]\n",
    "    list_content = list()\n",
    "    list_content_html = list()\n",
    "    for func in list_func:\n",
    "        try:\n",
    "            content, content_html = func(soup)\n",
    "        except:\n",
    "            content, content_html = np.nan, np.nan\n",
    "        list_content.append(content)\n",
    "        list_content_html.append(content_html)\n",
    "    df_content.loc[len(df_content)] = list_content\n",
    "    df_content_html.loc[len(df_content_html)] = list_content_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>div_in_article</th>\n",
       "      <th>one_div</th>\n",
       "      <th>all_div</th>\n",
       "      <th>from_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si les regards se tournent souvent vers les gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nos compétences\\n\\nÉnergie\\n\\nPrésentation\\nRé...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Si les regards se tournent souvent vers les gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment tuer l’innovation avec l’analyse finan...</td>\n",
       "      <td>Fiche de lecture\\nInnovation killers : how fin...</td>\n",
       "      <td>Fiche de lecture\\nInnovation killers : how fin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiche de lecture\\nInnovation killers : how fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ / Transformation numérique Les salariés et l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Une étude réalisée par l'ESN Inetum avec l'Ins...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/ MOBILITÉ\\n/ OS\\n/ PME\\n/ RÉSEAU\\n/ SÉCURITÉ\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quelles sont les obligations de publication ?\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quelles sont les obligations de publication ?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ondes électromagnétiques : Faut-il craindre la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connaître  l'Inserm\\n\\n\\n\\n\\n\\n\\nConnaître  l'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nLa recherche  à l'Inserm\\n\\n\\nLe continuum d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tLe 26\\nMai\\n2020‚ \\n\\t\\t\\t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expertises\\n\\nConseil en Marketing et Communic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La bonne connaissance des besoins de l’entrepr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiquement, la GPEC est un exercice mené d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiquement, la GPEC est un exercice mené d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compte Rendu de l’évènement : Big Data &amp; GPEC ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Compte Rendu de l’évènement : Big Data &amp; GPEC\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\t\\t\\t\\tMieux vivre la ménopause au travai...</td>\n",
       "      <td>Aurélien Leleux\\n\\nJanuary 20, 2020</td>\n",
       "      <td>L’innovation en RH est un thème de plus en plu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L’innovation en RH est un thème de plus en plu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\n\\t\\t\\t\\tMieux vivre la ménopause au travai...</td>\n",
       "      <td>Aurélien Leleux\\n\\nJanuary 20, 2020</td>\n",
       "      <td>Les chatbots, ou agents relationnels, sont dep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Les chatbots, ou agents relationnels, sont dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le management stratégique et le management opé...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n \\n\\n\\nQu'est-ce que le management ?\\n\\n\\nLe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Définition et explication\\n Définition et expl...</td>\n",
       "      <td>LinkedInTwitterFacebookE-mail</td>\n",
       "      <td>Définition et explication\\n\\nLa blockchain est...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Une blockchain publique peut donc être assimil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Le contexte législatif  Le contexte législatif...</td>\n",
       "      <td>Articles récents\\n\\n\\nRèglement intérieur du c...</td>\n",
       "      <td>Le contexte législatif \\nL’Autorisation de Pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le contexte législatif \\nL’Autorisation de Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brain Computer Interface</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Une interface neuronale directe (IND), ou Brai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Présentation des publication/recommandationsGu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sélectionnez un programme de formation\\n---Ate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Elus municipaux 2014 \\n\\n\\n                   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ressources communautaires\\nRéutilisations\\nDis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n                Article de presse\\n       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1-rne-cm.txt \\n\\n\\n                    txt\\n  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ressources communautaires\\nRéutilisations\\nDis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IA et Machine Learning : comment optimiser en ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EnjeuxDirecteur GénéralDirecteur des Ressource...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L’IA permet une planification basée sur les do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PME en croissance : peut-on prévoir les seuils...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outils de citation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nTypes de publications\\n\\n\\nRevues\\n\\n\\nThèse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Base de données : qu’est-ce que c’est ? Défini...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bastien L\\n24 janvier 2019\\nDossiers\\nCommenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus\\nVaccination\\nActualités\\nFinance\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus\\nVaccination\\nActualités\\nFinance\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Détecter des incidents cyber par Machine Learn...</td>\n",
       "      <td>Partager l'article sur FacebookPartager l'arti...</td>\n",
       "      <td>Derniers articles publiés dans la rubrique\\n  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Détecter des incidents cyber par Machine Learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AccÃ¨s rapide au contenu\\nHaut de page</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nZoom sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Accueil  Brand Talks  La Recherche Opérationne...</td>\n",
       "      <td>15 janvier 2021</td>\n",
       "      <td>Réussir\\n\\nvar block_tdi_2_670 = new tdBlock()...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nUn formidable outil d’aide à la décision\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Si les regards se tournent souvent vers les gr...   \n",
       "1   Comment tuer l’innovation avec l’analyse finan...   \n",
       "2   / / Transformation numérique Les salariés et l...   \n",
       "3                                                 NaN   \n",
       "4   Ondes électromagnétiques : Faut-il craindre la...   \n",
       "5   \\n\\n\\n\\t\\t\\t\\t\\t\\t\\tLe 26\\nMai\\n2020‚ \\n\\t\\t\\t...   \n",
       "6                                                 NaN   \n",
       "7   Compte Rendu de l’évènement : Big Data & GPEC ...   \n",
       "8   \\n\\n\\t\\t\\t\\tMieux vivre la ménopause au travai...   \n",
       "9   \\n\\n\\t\\t\\t\\tMieux vivre la ménopause au travai...   \n",
       "10                                                NaN   \n",
       "11  Définition et explication\\n Définition et expl...   \n",
       "12  Le contexte législatif  Le contexte législatif...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15  Elus municipaux 2014 \\n\\n\\n                   ...   \n",
       "16  1-rne-cm.txt \\n\\n\\n                    txt\\n  ...   \n",
       "17  IA et Machine Learning : comment optimiser en ...   \n",
       "18  PME en croissance : peut-on prévoir les seuils...   \n",
       "19  Base de données : qu’est-ce que c’est ? Défini...   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22  Détecter des incidents cyber par Machine Learn...   \n",
       "23                                                NaN   \n",
       "24  Accueil  Brand Talks  La Recherche Opérationne...   \n",
       "\n",
       "                                       div_in_article  \\\n",
       "0                                                 NaN   \n",
       "1   Fiche de lecture\\nInnovation killers : how fin...   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                 Aurélien Leleux\\n\\nJanuary 20, 2020   \n",
       "9                 Aurélien Leleux\\n\\nJanuary 20, 2020   \n",
       "10                                                NaN   \n",
       "11                      LinkedInTwitterFacebookE-mail   \n",
       "12  Articles récents\\n\\n\\nRèglement intérieur du c...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22  Partager l'article sur FacebookPartager l'arti...   \n",
       "23                                                NaN   \n",
       "24                                    15 janvier 2021   \n",
       "\n",
       "                                              one_div all_div  \\\n",
       "0   Nos compétences\\n\\nÉnergie\\n\\nPrésentation\\nRé...     NaN   \n",
       "1   Fiche de lecture\\nInnovation killers : how fin...     NaN   \n",
       "2   Une étude réalisée par l'ESN Inetum avec l'Ins...     NaN   \n",
       "3   Quelles sont les obligations de publication ?\\...     NaN   \n",
       "4   Connaître  l'Inserm\\n\\n\\n\\n\\n\\n\\nConnaître  l'...     NaN   \n",
       "5   Expertises\\n\\nConseil en Marketing et Communic...     NaN   \n",
       "6   Historiquement, la GPEC est un exercice mené d...     NaN   \n",
       "7                                                         NaN   \n",
       "8   L’innovation en RH est un thème de plus en plu...     NaN   \n",
       "9   Les chatbots, ou agents relationnels, sont dep...     NaN   \n",
       "10  Le management stratégique et le management opé...     NaN   \n",
       "11  Définition et explication\\n\\nLa blockchain est...     NaN   \n",
       "12  Le contexte législatif \\nL’Autorisation de Pro...     NaN   \n",
       "13                           Brain Computer Interface     NaN   \n",
       "14  Présentation des publication/recommandationsGu...     NaN   \n",
       "15  Ressources communautaires\\nRéutilisations\\nDis...     NaN   \n",
       "16  Ressources communautaires\\nRéutilisations\\nDis...     NaN   \n",
       "17  EnjeuxDirecteur GénéralDirecteur des Ressource...     NaN   \n",
       "18                                 Outils de citation     NaN   \n",
       "19                                                        NaN   \n",
       "20                                                        NaN   \n",
       "21                                                        NaN   \n",
       "22  Derniers articles publiés dans la rubrique\\n  ...     NaN   \n",
       "23             AccÃ¨s rapide au contenu\\nHaut de page     NaN   \n",
       "24  Réussir\\n\\nvar block_tdi_2_670 = new tdBlock()...     NaN   \n",
       "\n",
       "                                             from_tag  \n",
       "0   Si les regards se tournent souvent vers les gr...  \n",
       "1   Fiche de lecture\\nInnovation killers : how fin...  \n",
       "2   / MOBILITÉ\\n/ OS\\n/ PME\\n/ RÉSEAU\\n/ SÉCURITÉ\\...  \n",
       "3   Quelles sont les obligations de publication ?\\...  \n",
       "4   \\nLa recherche  à l'Inserm\\n\\n\\nLe continuum d...  \n",
       "5   La bonne connaissance des besoins de l’entrepr...  \n",
       "6   Historiquement, la GPEC est un exercice mené d...  \n",
       "7   Compte Rendu de l’évènement : Big Data & GPEC\\...  \n",
       "8   L’innovation en RH est un thème de plus en plu...  \n",
       "9   Les chatbots, ou agents relationnels, sont dep...  \n",
       "10  \\n \\n\\n\\nQu'est-ce que le management ?\\n\\n\\nLe...  \n",
       "11  Une blockchain publique peut donc être assimil...  \n",
       "12  Le contexte législatif \\nL’Autorisation de Pro...  \n",
       "13  Une interface neuronale directe (IND), ou Brai...  \n",
       "14  Sélectionnez un programme de formation\\n---Ate...  \n",
       "15  \\n\\n                Article de presse\\n       ...  \n",
       "16                                                     \n",
       "17  L’IA permet une planification basée sur les do...  \n",
       "18  \\nTypes de publications\\n\\n\\nRevues\\n\\n\\nThèse...  \n",
       "19  Bastien L\\n24 janvier 2019\\nDossiers\\nCommenta...  \n",
       "20  Coronavirus\\nVaccination\\nActualités\\nFinance\\...  \n",
       "21  Coronavirus\\nVaccination\\nActualités\\nFinance\\...  \n",
       "22  Détecter des incidents cyber par Machine Learn...  \n",
       "23                                      \\nZoom sur...  \n",
       "24  \\nUn formidable outil d’aide à la décision\\n\\n...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dernière fonction est celle qui renvoie le plus de résultats mais certains ne correspondent pas au contenu de l'article. Elle sera tout de même utilisée dans le fichier principal pour récupérer le contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
