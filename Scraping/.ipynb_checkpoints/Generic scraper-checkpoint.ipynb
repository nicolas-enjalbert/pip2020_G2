{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_generic(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Getting content\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li']\n",
    "    if soup.find('article') is not None:\n",
    "        content_html = soup.find('article')\n",
    "        if soup.find('article').find_all(list_balises, recursive = False):\n",
    "            content = soup.find('article').find_all(list_balises, string = True)\n",
    "            content = ' '.join(tag.text for tag in content)\n",
    "        else:\n",
    "            list_p = soup.find('article').find_all('div', recursive = 'False')\n",
    "            print([p.parent.name for p in list_p])\n",
    "            list_parent_p = [p.parent for p in list_p]\n",
    "            print(list_parent_p)\n",
    "            if len(set(list_parent_p)) == 1:\n",
    "                content_html = list_parent_p[0]\n",
    "                print(content_html)\n",
    "                content = ' '.join(\n",
    "                    tag.text for tag in content_html.children if tag.name in list_balises)\n",
    "            else:\n",
    "                content_html = soup.find('article')\n",
    "                content = [el.get_text() for el in list_parent_p]\n",
    "                content = ' '.join(content)\n",
    "    else:\n",
    "        list_div = list()\n",
    "        for el in soup.find_all('div'):\n",
    "            if el.find_all('p', recursive = False):\n",
    "                list_div.append(el)\n",
    "        index_max = np.argmax([len(block.find_all('p')) for block in list_div])\n",
    "        content_html = list_div[index_max]\n",
    "        content = ' '.join(\n",
    "            tag.text for tag in content_html.children if tag.name in list_balises)\n",
    "    content = content.replace('\\xa0', '').replace('\\t', '').replace('\\r', '').strip()\n",
    "    content_html_str = str(content_html)\n",
    "    \n",
    "    # Getting date of publication\n",
    "    if soup.find(\"meta\", {\"property\"\n",
    "                          \"article:modified_time\"}) is not None:\n",
    "        date = soup.find(\"meta\", {\"property\"\n",
    "                                  \"article:modified_time\"})[\"content\"]\n",
    "    elif soup.find(\"meta\", {\"property\": \"article:published_time\"}) is not None:\n",
    "        date = soup.find(\"meta\", {\"property\": \"article:published_time\"})[\n",
    "            \"content\"]\n",
    "    else:\n",
    "        date = datetime.date.today()\n",
    "\n",
    "    # Getting language\n",
    "    art_lang = TextBlob(content).detect_language()\n",
    "\n",
    "    # Getting title\n",
    "    if soup.find(\"meta\", {\"property\": \"og:title\"}) is not None:\n",
    "        title = soup.find(\"meta\", {\"property\": \"og:title\"})[\"content\"]\n",
    "    elif soup.find(\"title\") is not None:\n",
    "        title = soup.find(\"title\").get_text()\n",
    "    else:\n",
    "        title = np.nan\n",
    "\n",
    "    # Getting article url\n",
    "    if soup.find(\"meta\", {\"property\": \"og:url\"}) is not None:\n",
    "        art_url = soup.find(\"meta\", {\"property\": \"og:url\"})[\"content\"]\n",
    "    elif soup.find(\"link\", rel=\"canonical\"):\n",
    "        art_url = soup.find(\"link\", rel=\"canonical\")[\"href\"]\n",
    "    else:\n",
    "        art_url = url\n",
    "\n",
    "    # Getting source url\n",
    "    src_url = BigScraper.get_base_url(art_url)\n",
    "\n",
    "    # Getting source name\n",
    "    if soup.find(\"meta\", {\"property\": \"og:site_name\"}) is not None:\n",
    "        src_name = soup.find(\"meta\", {\"property\": \"og:site_name\"})[\"content\"]\n",
    "    else:\n",
    "        src_name = art_url.split(r\"//\")\n",
    "        if \"http\" in src_name[0]:\n",
    "            src_name = src_name[1]\n",
    "        else:\n",
    "            src_name = src_name[0]\n",
    "        src_name = src_name.split(r\"/\")[0]\n",
    "        for i in [\"fr.\", \"www.\", \"www2.\", \".org\", \".fr\", \".eu\", \".net\", \".com\"]:\n",
    "            src_name = src_name.replace(i, \"\")\n",
    "\n",
    "    # Source type\n",
    "    src_type = \"xpath_source\"\n",
    "\n",
    "    # Getting image\n",
    "    if soup.find(\"meta\", {\"property\": \"og:image\"}) is not None:\n",
    "        art_img = soup.find(\"meta\", {\"property\": \"og:image\"})[\"content\"]\n",
    "    else:\n",
    "        art_img = np.nan\n",
    "\n",
    "    # Getting author\n",
    "    if soup.find(\"meta\", {\"name\": \"author\"}) is not None:\n",
    "        art_auth = soup.find(\"meta\", {\"name\": \"author\"})[\"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"name\": \"twitter:data1\"}) is not None:\n",
    "        art_auth = soup.find(\"meta\", {'name': \"twitter:data1\"})[\n",
    "            \"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"property\": \"sage:author\"}) is not None:\n",
    "        art_auth = soup.find(\"meta\", {\"property\": \"sage:author\"})[\n",
    "            \"content\"].split(\",\")\n",
    "    else:\n",
    "        art_auth = np.nan\n",
    "\n",
    "    # Getting tags\n",
    "    if soup.find(\"meta\", {\"name\": \"keywords\"}) is not None:\n",
    "        art_tag = soup.find(\"meta\", {\"name\": \"keywords\"})[\"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"sage\": \"sageTags\"}) is not None:\n",
    "        art_tag = soup.find(\"meta\", {\"sage\": \"sageTags\"})[\"content\"].split(\",\")\n",
    "    elif soup.find(\"meta\", {\"property\": \"article:tag\"}) is not None:\n",
    "        art_tag = soup.find(\"meta\", {\"property\": \"article:tag\"})[\n",
    "            \"content\"].split(\",\")\n",
    "    else:\n",
    "        art_tag = np.nan\n",
    "\n",
    "    return [content, content_html_str, date, art_lang, title, art_url, src_url, src_name, src_type, art_img, art_auth, art_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    list_balises = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em',\n",
    "                    'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p', 'span', 'ul', 'li']\n",
    "    if soup.find('article') is not None:\n",
    "        content_html = soup.find('article')\n",
    "        if soup.find('article').find_all(list_balises, recursive = False):\n",
    "            content = soup.find('article').find_all(list_balises, string = True)\n",
    "            content = ' '.join(tag.text for tag in content)\n",
    "        else:\n",
    "            list_p = soup.find('article').find_all('div', recursive = 'False')\n",
    "            print([p.parent.name for p in list_p])\n",
    "            list_parent_p = [p.parent for p in list_p]\n",
    "            print(list_parent_p)\n",
    "            if len(set(list_parent_p)) == 1:\n",
    "                content_html = list_parent_p[0]\n",
    "                print(content_html)\n",
    "                content = ' '.join(\n",
    "                    tag.text for tag in content_html.children if tag.name in list_balises)\n",
    "            else:\n",
    "                content_html = soup.find('article')\n",
    "                content = [el.get_text() for el in list_parent_p]\n",
    "                content = ' '.join(content)\n",
    "    else:\n",
    "        list_div = list()\n",
    "        for el in soup.find_all('div'):\n",
    "            if el.find_all('p', recursive = False):\n",
    "                list_div.append(el)\n",
    "        index_max = np.argmax([len(block.find_all('p')) for block in list_div])\n",
    "        content_html = list_div[index_max]\n",
    "        content = ' '.join(\n",
    "            tag.text for tag in content_html.children if tag.name in list_balises)\n",
    "    content = content.replace('\\xa0', '').replace('\\t', '').replace('\\r', '').strip()\n",
    "    return content_html, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = ['https://www.fnccr.asso.fr/article/big-data-territorial-publication-de-letude-de-la-fnccr/',\n",
    "        'https://www.banquedesterritoires.fr/big-data-territorial-la-gestion-des-donnees-un-enjeu-davenir-pour-les-collectivites', \n",
    "        'https://www.theinnovation.eu/comment-tuer-linnovation-avec-lanalyse-financiere/45',\n",
    "        'https://www.lemondeinformatique.fr/actualites/lire-les-salaries-et-les-dirigeants-percoivent-differement-la-transformation-digitale-81352.html',\n",
    "        'https://www.cnil.fr/fr/les-collectivites-territoriales-et-lopen-data-concilier-ouverture-des-donnees-et-protection-des',\n",
    "        'https://www.inserm.fr/actualites-et-evenements/actualites/ondes-electromagnetiques-faut-il-craindre-5g',\n",
    "        'https://www.parlonsrh.com/raisons-utiliser-lintelligence-artificielle-dans-gestion-gpec/',\n",
    "        'https://www.myrhline.com/actualite-rh/de-la-gpec-et-au-workforce-planning-les-5-evolutions-a-connaitre.html',\n",
    "        'https://grh-multi.net/fr/2016/05/compte-rendu-de-levenement-big-data-gpec/',\n",
    "        'https://changethework.com/gestion-paie-innovations/',\n",
    "        'https://changethework.com/chatbot-rh-recrutement/',\n",
    "        'http://sabbar.fr/management/le-management-strategique-et-le-management-operationnel/#:~:text=Le%20management%20op%C3%A9rationnel%20correspond%20aux,pour%20atteindre%20les%20objectifs%20fix%C3%A9s.',\n",
    "        # 'http://uis.unesco.org/fr/topic/donnees-sur-linnovation',\n",
    "        'http://www.linternaute.com/ville/classement/villes/population',\n",
    "        'http://www.territorial.fr/PAR_TPL_IDENTIFIANT/722/TPL_CODE/TPL_OUVR_NUM_FICHE/PAG_TITLE/La+gestion+en+AP-CP+et+la+programmation+des+investissements/53-dossiers-d-expert.htm',\n",
    "        'https://blockchainfrance.net/decouvrir-la-blockchain/c-est-quoi-la-blockchain/',\n",
    "        'https://citoyen-ne-s-de-marseille.fr/cest-quoi-les-autorisations-de-programmes/',\n",
    "        'https://dataanalyticspost.com/Lexique/algorithmes-genetiques/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = URLs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dataanalyticspost.com/Lexique/algorithmes-genetiques/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Algorithmes génétiques : Cette famille de techniques s’inspire de la théorie Darwinienne de l’évolution pour résoudre des problèmes d’optimisation. La théorie de l’évolution présentée par Charles Darwin en 1859 dans son livre “l’Origine des espèces”, repose sur trois principes clés : l’hérédité, la variation et la sélection. Ainsi, lorsqu’un organisme vivant se reproduit, il transmet ses caractéristiques à ses descendants, à travers ses gènes. Cependant l’hérédité des caractères n’est pas parfaite, les gènes peuvent subir des mutations et les descendants peuvent donc présenter des variations de caractères. Par conséquent, les différents individus appartenant à une population d’organismes vivants ne sont pas tous identiques, et certains d’entre eux peuvent avoir des variations qui leur permettent de mieux survivre et de se reproduire davantage dans un certain environment. Ces individus ont donc un avantage sélectif, plus de chances de transmettre leurs gènes à la génération future. À travers ce processus, les organismes s’adaptent à leur environnement, au cours des générations. Les algorithmes génétiques, et les algorithmes évolutionnaires en général, reposent sur ces principes. Comment fonctionnent-ils ? Tout d’abord, on cherche à représenter les solutions possibles du problème d’optimisation sous la forme d’un génome, puis on génère une population de solutions potentielles au problème donné, on sélectionne ensuite les solutions les plus performantes vis à vis de la tâche à optimiser, on crée alors une nouvelle population en copiant à l’identique les solutions sélectionnées, enfin on applique des opérateurs de variation aux génomes des individus de la nouvelle population, afin de créer des solutions différentes. La population d’enfants devient à son tour la population parentale, et on itère la même procédure jusqu’à ce qu’une solution satisfaisante soit trouvée. En pratique il existe un grand nombre de façons de représenter les solutions potentielles à un problème, les codages les plus courants sont par exemple les vecteurs de nombres (binaires, entiers ou réels) et les graphes (par exemple des structures analogues aux arbres de décision). De même, il existe différentes méthodes de sélection (tournoi, par rang, uniforme…) et de variation (mutations ponctuelles, cross-over), et le bon choix de ces différents aspects est crucial pour obtenir des résultats pertinents. Ces algorithmes permettent d’explorer l’espace de solutions possibles de manière non exhaustive, afin d’obtenir une solution satisfaisante. Par conséquent, ils sont particulièrement utiles dans le cas d’espaces de très grande taille, présentant des optima locaux, difficiles à explorer avec des algorithmes déterministes d’optimisation. De plus, ces algorithmes s’adaptent facilement à des espaces de données qui changent dans le temps. A contrario, leur principal inconvénient est que leurs résultats dépendent fortement du choix des différents éléments qui les constituent ainsi que des paramètres associés.   Cette vidéo schématise comment des organismes artificiels apprennent à marcher grâce à des algorithmes génétiques.  La figure suivante illustre le fonctionnement de ces algorithmes. Les individus sont ici figurés par des ellipses de couleur, et la fonction à optimiser (axe “fitness”) dépend de la couleur et de la forme des individus. Les qualités de certains individus sont illustrées sur la courbe selon ce maillage en trois dimensions (qualité, couleur, forme) : on voit ainsi que l’ellipse rouge a un très fort avantage sélectif, contrairement à l’ellipse vert pâle, l’ellipse bleu présentant une qualité moyenne. Les trois images suivantes correspondent respectivement à la population initiale, à celle à mis parcours et à la population finale. On constate qu’au fur et à mesure, les caractéristiques des ellipses évoluent vers celles du meilleur individu possible.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(url)\n",
    "get_content(url)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"skip-links position-fixed\">\n",
      " <ul class=\"list-inline m-0 p-0\">\n",
      "  <li class=\"list-inline-item\">\n",
      "   <a class=\"skip-links__link visually-hidden focusable\" data-a11y-dialog-show=\"modal-dialog-access-config\" data-target=\"#a11yModal\" data-toggle=\"modal\" href=\"#modal_access\" role=\"button\">\n",
      "    Open accessibility window\n",
      "   </a>\n",
      "  </li>\n",
      "  <li class=\"list-inline-item\">\n",
      "   <a class=\"skip-links__link visually-hidden focusable\" href=\"#block-navigationprincipale\">\n",
      "    Aller au menu principal\n",
      "   </a>\n",
      "  </li>\n",
      "  <li class=\"list-inline-item\">\n",
      "   <a class=\"skip-links__link visually-hidden focusable\" href=\"#main-content\">\n",
      "    Aller au contenu principal\n",
      "   </a>\n",
      "  </li>\n",
      " </ul>\n",
      "</div>\n",
      "\n",
      "\n",
      "\n",
      "<ul class=\"list-inline m-0 p-0\">\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" data-a11y-dialog-show=\"modal-dialog-access-config\" data-target=\"#a11yModal\" data-toggle=\"modal\" href=\"#modal_access\" role=\"button\"> Open accessibility window </a>\n",
      "</li>\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#block-navigationprincipale\"> Aller au menu principal </a>\n",
      "</li>\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#main-content\"> Aller au contenu principal </a>\n",
      "</li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<ul class=\"list-inline m-0 p-0\">\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" data-a11y-dialog-show=\"modal-dialog-access-config\" data-target=\"#a11yModal\" data-toggle=\"modal\" href=\"#modal_access\" role=\"button\"> Open accessibility window </a>\n",
      "</li>\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#block-navigationprincipale\"> Aller au menu principal </a>\n",
      "</li>\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#main-content\"> Aller au contenu principal </a>\n",
      "</li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" data-a11y-dialog-show=\"modal-dialog-access-config\" data-target=\"#a11yModal\" data-toggle=\"modal\" href=\"#modal_access\" role=\"button\"> Open accessibility window </a>\n",
      "</li>\n",
      "\n",
      "\n",
      "<a class=\"skip-links__link visually-hidden focusable\" data-a11y-dialog-show=\"modal-dialog-access-config\" data-target=\"#a11yModal\" data-toggle=\"modal\" href=\"#modal_access\" role=\"button\"> Open accessibility window </a>\n",
      " Open accessibility window \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#block-navigationprincipale\"> Aller au menu principal </a>\n",
      "</li>\n",
      "\n",
      "\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#block-navigationprincipale\"> Aller au menu principal </a>\n",
      " Aller au menu principal \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<li class=\"list-inline-item\">\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#main-content\"> Aller au contenu principal </a>\n",
      "</li>\n",
      "\n",
      "\n",
      "<a class=\"skip-links__link visually-hidden focusable\" href=\"#main-content\"> Aller au contenu principal </a>\n",
      " Aller au contenu principal \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "all_div = soup.find_all('div')\n",
    "print(all_div[0].prettify())\n",
    "for i in all_div[0].children:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De la GPEC et au Workforce Planning : Les 5 évolutions à connaître\n",
      "Une philosophie nouvelle\n",
      "Une philosophie nouvelle\n",
      "L’accélération de la transformation des métiers, couplée à un environnement économique incertain, conduit à réinventer l’approche GPEC pour qu’elle réponde à des questions opérationnelles d’anticipation des besoins en compétences et d’évolution des effectifs. Il s’agit de fournir aux équipes RH des outils de pilotage identiques à ceux déployés dans le reste de l’entreprise afin qu’elles puissent modéliser rapidement les impacts RH des décisions stratégiques ou des ruptures d’activité comme celles que nous avons vécus avec la crise sanitaire. L’exercice d’anticipation est fait régulièrement et donne lieu à des plans d’actions opérationnels suivis par les RRH et les managers grâce au outils digitaux.\n",
      "La fin des « référentiels statiques »\n",
      "La fin des « référentiels statiques »\n",
      "Pour que cela fonctionne, les entreprises ne peuvent plus passer 2 à 3 ans à construire et déployer leur référentiel métiers et compétences. Elles doivent gagner en agilité en s’appuyant sur des bases de données externes nourries par une approche marché, enrichies par l’intelligence artificielle. Ces bases de données permettent de se concentrer sur la création d’une vision commune de ce que seront les métiers et compétences dans son entreprise demain. En parallèle, les collaborateurs déclarent leurs compétences de manière dynamique. Ils mettent ainsi à jour la cartographie de l’existant au fil de l’eau.\n",
      "L’exploitation des historiques\n",
      "L’exploitation des historiques\n",
      "Les projections GPEC sont en général réalisées sur la base d’un tableau excel avec l’effectif actuel, l’effectif cible, la prévision des entrées/sorties renseignés par le métier. Les historiques de données sont peu ou pas du tout exploités. La mise en place des Data Lake permet aujourd’hui aux entreprises d’exploiter les données d’historique pour construire des prévisions plus fiables et se donner les moyens de mieux anticiper les évolutions.\n",
      "La prise en compte de la réalité des individus\n",
      "La prise en compte de la réalité des individus\n",
      "Les exercices d’analyse de l’existant et de vieillissement des compétences étaient souvent faits à dire d’expert. Les cartographie de compétences aujourd’hui déployées dans de nombreuses entreprises permettent de mieux connaître l’état des lieux des compétences et la réalité des métiers. L’analyse de l’existant et sa projection sont désormais plus riches et plus fiables. Les systèmes permettent aux RH et Managers de faire le lien avec l’évolution des métiers et compétences pour déployer des plans d’actions individuels adaptés (Formation / Mobilité / …).\n",
      "L’apport des algorithmes \n",
      "L’apport des algorithmes \n",
      "La brutalité de la crise du COVID nous a montré les limites des approches traditionnelles. Nombreux sont ceux qui ont mis des semaines à répondre à des questions aussi simples que : « Que se passe-t-il si on gèle les recrutements pendant 6 mois ? », « Quelles sont les compétences clefs à maintenir sur site ? »,… Les solutions actuelles proposent des algorithmes de prévisions qui permettent de répondre à ces questions plus rapidement. Progressivement, les équipes peuvent se concentrer sur l’analyse et les plans d’actions. Les solutions les plus évoluées proposent des datavisualisations et des alertes permettant d’exploiter pleinement l’apport du Big Data et de l’IA.\n",
      " \n",
      " \n",
      "Carole MENGUY\n",
      "Carole MENGUY\n",
      " \n",
      " \n",
      "Articles RH relatifs \n",
      " \n",
      "Comment va évoluer le digital workspace ?\n",
      "Lier management innovant et RH  avec l’Odyssée Managériale\n",
      "[Actualités RH 2021] Ce qui change en Janvier\n",
      "L’écologie d’aller au travail avec  le Forfait mobilités durables\n",
      "Comment maintenir la culture d’entreprise en télétravail ?\n",
      "Emploi des personnes en situation de handicap : 6 nouvelles mesures annoncées\n",
      "à propos\n",
      "Dossiers RH\n",
      "Dossier transformation digitale RH\n",
      " \n",
      "Livres blancs et guides RH\n",
      "Suivez-nous\n",
      "Newsletter RH\n",
      " \n",
      "Le média des professionnels des Ressources Humaines. “Toute l’actualité RH et les tendances des ressources humaines d’aujourd’hui et de demain”\n",
      "© DESIGNRH 2019 – Tous droits réservés\n",
      "© DESIGNRH 2019 – Tous droits réservés\n",
      "Mentions légales\n",
      "Comment va évoluer le digital workspace ?\n"
     ]
    }
   ],
   "source": [
    "for el in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'strong', 'i', 'em', 'pre', 'mark', 'small', 'del', 's', 'ins', 'u', 'sub', 'sup', 'dfn', 'p'], string = True):\n",
    "    print(el.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historiquement, la GPEC est un exercice mené dans les entreprises pour répondre à des impératifs légaux de dialogue social. L’exercice, réalisé en moyenne tous les 3 ans, est souvent perçu comme théorique, chronophage et fastidieux.  Pourtant, depuis quelques mois, le terme de Workforce Planning revient sur le devant de la scène pour matérialiser la nouvelle dynamique de la GPEC. Voici les 5 évolutions à maîtriser pour comprendre l’évolution en cours :Une philosophie nouvelleL’accélération de la transformation des métiers, couplée à un environnement économique incertain, conduit à réinventer l’approche GPEC pour qu’elle réponde à des questions opérationnelles d’anticipation des besoins en compétences et d’évolution des effectifs. Il s’agit de fournir aux équipes RH des outils de pilotage identiques à ceux déployés dans le reste de l’entreprise afin qu’elles puissent modéliser rapidement les impacts RH des décisions stratégiques ou des ruptures d’activité comme celles que nous avons vécus avec la crise sanitaire. L’exercice d’anticipation est fait régulièrement et donne lieu à des plans d’actions opérationnels suivis par les RRH et les managers grâce au outils digitaux.La fin des « référentiels statiques »Pour que cela fonctionne, les entreprises ne peuvent plus passer 2 à 3 ans à construire et déployer leur référentiel métiers et compétences. Elles doivent gagner en agilité en s’appuyant sur des bases de données externes nourries par une approche marché, enrichies par l’intelligence artificielle. Ces bases de données permettent de se concentrer sur la création d’une vision commune de ce que seront les métiers et compétences dans son entreprise demain. En parallèle, les collaborateurs déclarent leurs compétences de manière dynamique. Ils mettent ainsi à jour la cartographie de l’existant au fil de l’eau.L’exploitation des historiquesLes projections GPEC sont en général réalisées sur la base d’un tableau excel avec l’effectif actuel, l’effectif cible, la prévision des entrées/sorties renseignés par le métier. Les historiques de données sont peu ou pas du tout exploités. La mise en place des Data Lake permet aujourd’hui aux entreprises d’exploiter les données d’historique pour construire des prévisions plus fiables et se donner les moyens de mieux anticiper les évolutions.La prise en compte de la réalité des individusLes exercices d’analyse de l’existant et de vieillissement des compétences étaient souvent faits à dire d’expert. Les cartographie de compétences aujourd’hui déployées dans de nombreuses entreprises permettent de mieux connaître l’état des lieux des compétences et la réalité des métiers. L’analyse de l’existant et sa projection sont désormais plus riches et plus fiables. Les systèmes permettent aux RH et Managers de faire le lien avec l’évolution des métiers et compétences pour déployer des plans d’actions individuels adaptés (Formation / Mobilité / …).L’apport des algorithmes La brutalité de la crise du COVID nous a montré les limites des approches traditionnelles. Nombreux sont ceux qui ont mis des semaines à répondre à des questions aussi simples que : « Que se passe-t-il si on gèle les recrutements pendant 6 mois ? », « Quelles sont les compétences clefs à maintenir sur site ? »,… Les solutions actuelles proposent des algorithmes de prévisions qui permettent de répondre à ces questions plus rapidement. Progressivement, les équipes peuvent se concentrer sur l’analyse et les plans d’actions. Les solutions les plus évoluées proposent des datavisualisations et des alertes permettant d’exploiter pleinement l’apport du Big Data et de l’IA.Vous l’aurez compris la GPEC, comme l’ensemble des pratiques RH, se transforme sous l’effet du digital et de l’IA. C’est un peu comme passer de la photo à la vidéo. N’hésitez pas à contacter les équipes de WiserSKILLS si vous souhaitez en savoir plus. Carole MENGUY Articles RH relatifs Programme : Semaine de la transformation digitale RH Janvier 2021 Sur quoi repose la croissance massive du marché des logiciels RH ? Les logiciels RH – ou SIRH (Système d’Information des Ressources…PartagezTweetezPartagez0 Partages      Carole MENGUYCompetenceGPECwiserskillsworkforce planning\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "l = [list(j) for i, j in groupby(parents)]\n",
    "idx = np.argmax(map(len, l))\n",
    "print(list(set(l[idx]))[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
