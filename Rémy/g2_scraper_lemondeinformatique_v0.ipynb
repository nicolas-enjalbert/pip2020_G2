{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /srv/conda/envs/notebook/lib/python3.6/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk>=3.1->textblob) (4.55.1)\n",
      "Requirement already satisfied: regex in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk>=3.1->textblob) (2020.11.13)\n",
      "Requirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
      "Requirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: bs4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /srv/conda/envs/notebook/lib/python3.6/site-packages (from beautifulsoup4->bs4) (2.1)\n",
      "https://www.lemondeinformatique.fr/actualites/lire-le-cloud-hybride-une-garantie-d-agilite-pour%C2%A0ceridian%C2%A0-81109.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_extract_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>... Pour aller plus loin dans sa transformatio...</td>\n",
       "      <td>&lt;p class=\"title\"&gt;...&lt;/p&gt; &lt;p class=\"description...</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>fr</td>\n",
       "      <td>Le cloud hybride, une garantie d'agilité pour ...</td>\n",
       "      <td>https://www.lemondeinformatique.fr/actualites/...</td>\n",
       "      <td>lemondeinformatique</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>https://www.lemondeinformatique.fr/</td>\n",
       "      <td>https://images.itnewsinfo.com/lmi/articles/gra...</td>\n",
       "      <td>John Edwards, Network World (adaptation Jean E...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         art_content  \\\n",
       "0  ... Pour aller plus loin dans sa transformatio...   \n",
       "\n",
       "                                    art_content_html art_extract_datetime  \\\n",
       "0  <p class=\"title\">...</p> <p class=\"description...           2020-11-24   \n",
       "\n",
       "  art_lang                                          art_title  \\\n",
       "0       fr  Le cloud hybride, une garantie d'agilité pour ...   \n",
       "\n",
       "                                             art_url             src_name  \\\n",
       "0  https://www.lemondeinformatique.fr/actualites/...  lemondeinformatique   \n",
       "\n",
       "       src_type                              src_url  \\\n",
       "0  xpath_source  https://www.lemondeinformatique.fr/   \n",
       "\n",
       "                                             src_img  \\\n",
       "0  https://images.itnewsinfo.com/lmi/articles/gra...   \n",
       "\n",
       "                                            art_auth   art_tag  \n",
       "0  John Edwards, Network World (adaptation Jean E...  Business  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Mon Jan 4 11:43:14 2021\n",
    "Group 2\n",
    "@authors: Rémy Lapeyre\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install textblob\n",
    "!pip install bs4\n",
    "from textblob import TextBlob\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_Title(url : str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui a partir d'un url parse le dom HTLM et return le titre\n",
    "  \"\"\"\n",
    "  req = get(url)\n",
    "  html_soup = BeautifulSoup(req.text, 'html.parser')\n",
    "  title = html_soup.find(itemprop = \"headline\").text\n",
    "  return title\n",
    "\n",
    "def get_img(url : str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui a partir d'un url parse le dom HTLM et return une image\n",
    "  \"\"\"\n",
    "  req = get(url)\n",
    "  html_soup = BeautifulSoup(req.text, 'html.parser')\n",
    "  image = html_soup.find(itemprop = \"image\")['src']\n",
    "  return image\n",
    "\n",
    "def get_Date(url : str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui a partir d'un url parse le dom HTLM et return la date de mise en ligne de l'article\n",
    "  \"\"\"\n",
    "  req = get(url)\n",
    "  html_soup = BeautifulSoup(req.text, 'html.parser')\n",
    "  Date = html_soup.find(\"time\",{\"class\":\"date\"})['content']\n",
    "  return Date\n",
    "\n",
    "def get_Author(url : str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui a partir d'un url parse le dom HTLM et return l'auteur de l'article\n",
    "  \"\"\"\n",
    "  req = get(url)\n",
    "  html_soup = BeautifulSoup(req.text, 'html.parser')\n",
    "  author = html_soup.find(itemprop = \"name\").text\n",
    "  return author\n",
    "\n",
    "def get_Tag(url : str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui a partir d'un url parse le dom HTLM et return le tag\n",
    "  \"\"\"\n",
    "  req = get(url)\n",
    "  html_soup = BeautifulSoup(req.text, 'html.parser')\n",
    "  tag = html_soup.find(\"a\",{'rel':\"category\"}).text\n",
    "  return tag\n",
    "\n",
    "def get_Content(url :str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui a partir d'un url parse le dom HTML et return le content et le content html\n",
    "  \"\"\"\n",
    "  req = get(url)\n",
    "  html_soup = BeautifulSoup(req.text, 'html.parser')\n",
    "  paragraphe = html_soup.find_all('p')\n",
    "  content_html=\" \".join([str(x) for x in paragraphe])\n",
    "  content=\" \".join([x.text for x in paragraphe])\n",
    "  return content, content_html\n",
    "\n",
    "def get_Langue(url : str) -> str :\n",
    "  \"\"\"\n",
    "    fonction qui à partir d'un url parse le dom HTML et return la langue\n",
    "  \"\"\"\n",
    "  a = TextBlob(get_Title(url))\n",
    "  langue = a.detect_language()\n",
    "  return langue\n",
    "\n",
    "def scraping(url : str) -> tuple :\n",
    "  \"\"\"\n",
    "    fonction qui à partir d'un url return toutes l'ensemble des données de la page nettoyées sous forme de tuple \n",
    "  \"\"\"\n",
    "  art_content , art_content_html \t= get_Content(url)\n",
    "  art_extract_datetime = get_Date(url)\n",
    "  art_lang = get_Langue(url)\n",
    "  art_title =\tget_Title(url)\n",
    "  art_url = url\t\n",
    "  src_name = 'lemondeinformatique'\n",
    "  src_type = 'xpath_source' \t\n",
    "  src_url = 'https://www.lemondeinformatique.fr/'\t\t\n",
    "  src_img = get_img(url)\n",
    "  art_auth = get_Author(url)\n",
    "  art_tag = get_Tag(url)\n",
    "  return art_content,art_content_html,art_extract_datetime,art_lang,art_title,art_url,src_name,src_type,src_url,src_img,art_auth,art_tag\n",
    "\n",
    "url=input()\n",
    "d = {'art_content' : [scraping(url)[0]],\n",
    "     'art_content_html' : [scraping(url)[1]],\n",
    "     'art_extract_datetime' : [scraping(url)[2]],\n",
    "     'art_lang' : [scraping(url)[3]],\n",
    "     'art_title' : [scraping(url)[4]],\n",
    "     'art_url' : [scraping(url)[5]],\n",
    "     'src_name' : [scraping(url)[6]],\n",
    "     'src_type' : [scraping(url)[7]],\n",
    "     'src_url' : [scraping(url)[8]],\n",
    "     'src_img' : [scraping(url)[9]],\n",
    "     'art_auth' : [scraping(url)[10]],\n",
    "     'art_tag' : [scraping(url)[11]]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
