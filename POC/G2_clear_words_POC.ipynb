{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G2_clear_words_POC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GhhNn_UMeHd"
      },
      "source": [
        "# **Relevancy score**\r\n",
        "\r\n",
        "Authors : F.C, S.B\r\n",
        "\r\n",
        "Date : January 13, 2021\r\n",
        "\r\n",
        "**POC : depuis un data frame, si il y a des mots en commun entre les requêtes et le titre ou entre les requêtes et le résumé, les ajouter dans une nouvelle colonne de DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qz37Qvo6sYO",
        "outputId": "cf36d24d-571d-46bb-e108-b42516fe17ef"
      },
      "source": [
        "!pip install deplacy\r\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deplacy\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/8a/d5417f6f4c6e8d8da5a1e31d3874e3c37ff06362657b8b185405148b6566/deplacy-1.8.8-py3-none-any.whl\n",
            "Installing collected packages: deplacy\n",
            "Successfully installed deplacy-1.8.8\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=93829b2127086e36a33dd26b3d4e3e9d08617e2464b23f413755341c27bcfe03\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kzyr_6n0/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2Am6Wy6uTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4779e54-6441-40ab-ca5c-b3de0467a626"
      },
      "source": [
        "import pandas as pd\r\n",
        "import pkg_resources,imp\r\n",
        "imp.reload(pkg_resources)\r\n",
        "import spacy\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "nlp=spacy.load(\"fr_core_news_sm\")\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "stopword=nltk.corpus.stopwords.words('french')\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.stem.snowball import FrenchStemmer\r\n",
        "stemmer = FrenchStemmer()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4pgmAXi635F"
      },
      "source": [
        "wn=nltk.WordNetLemmatizer()\r\n",
        "def tokenize(text):\r\n",
        "    tokens = re.split('\\W+', text) #W+ means a word character or - can go there\r\n",
        "    return tokens\r\n",
        "def remove_stopwords(tokenzed_list):\r\n",
        "    text=[word for word in tokenzed_list if word not in stopword]\r\n",
        "    return text\r\n",
        "def lemmatizing(tokenized_text):\r\n",
        "    texte=[]\r\n",
        "    for elem in tokenized_text:\r\n",
        "      texte.append(stemmer.stem(elem))\r\n",
        "    return texte\r\n",
        "def return_mean_embedding(sentence):\r\n",
        "    # Tokeniser la phrase\r\n",
        "    doc = nlp(sentence)\r\n",
        "    # Retourner la moyenne des vecteurs pour chaque phrase\r\n",
        "    return np.mean([(X.vector) for X in doc], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LLdsXJi638K"
      },
      "source": [
        "def return_word_embedding(sentence):\r\n",
        "    # Tokeniser la phrase\r\n",
        "    doc = nlp(sentence)\r\n",
        "    # Retourner le vecteur lié à chaque token\r\n",
        "    return [(X.vector) for X in doc]\r\n",
        "def return_token(sentence):\r\n",
        "    # Tokeniser la phrase\r\n",
        "    doc = nlp(sentence)\r\n",
        "    # Retourner le texte de chaque token\r\n",
        "    return [X.text for X in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC0def4mqbbW",
        "outputId": "e6452d0f-8db2-4392-82a5-c410d89b3ace"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8fxJrNhq8NQ"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/df_test.csv',delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRm4yZ-h-zvI"
      },
      "source": [
        "df_test['query'][0]='(machine learning AND test) OR (adorer AND du futur AND ntm) OR (adorer AND dog)'\r\n",
        "df_test['resume'][0]='adorer le machine learning et du futur'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoDID6iH-aq9"
      },
      "source": [
        "df_test['mots'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACuymZ-ZFo6m"
      },
      "source": [
        "df_new=pd.read_csv('/content/drive/My Drive/df_test.csv',delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tITJYnA0HxBd"
      },
      "source": [
        "df_new['query'][0]='(machine learning AND test) OR (adorer AND du futur AND ntm) OR (adorer AND dog)'\r\n",
        "df_new['resume'][0]='adorer le machine learning et du futur'\r\n",
        "df_new['mots'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "SIcdF7GfG17a",
        "outputId": "031cd902-fa5c-454a-f0b4-064f36ba9c41"
      },
      "source": [
        "#on a deux data frame, un qui fera les comparaisons un qui gardera les mots d'origine\r\n",
        "\r\n",
        "df_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>query</th>\n",
              "      <th>title</th>\n",
              "      <th>resume</th>\n",
              "      <th>mots</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>(machine learning AND test) OR (adorer AND du ...</td>\n",
              "      <td>Machine learning and the new innovation paradigm</td>\n",
              "      <td>adorer le machine learning et du futur</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machine learning AND innovation</td>\n",
              "      <td>Machine learning and the new innovation paradigm</td>\n",
              "      <td>Machine learning is very innovative. It's...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ... mots\n",
              "0  https://graylinegroup.com/machine-learning-and...  ...     \n",
              "1  https://graylinegroup.com/machine-learning-and...  ...     \n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHXPlzIsFXvR"
      },
      "source": [
        "df_test['title'] = [x.lower() for x in df_test.title]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeGsTDNb_pOG"
      },
      "source": [
        "for i in range (len(df_test)):\r\n",
        "  df_test['query'][i] = df_test['query'][i].lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txve4Eko_Ba4",
        "outputId": "af5a8496-ba43-4460-8243-69f246247723"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "import pandas as pd\r\n",
        "import pickle\r\n",
        "import time\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stop_words = set(stopwords.words('french'))\r\n",
        "from nltk.stem import LancasterStemmer\r\n",
        "import numpy as np\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C0PpMMH-bkL",
        "outputId": "b3888cb1-4c1e-4b17-ed98-9beb43ad7c95"
      },
      "source": [
        "from nltk.stem import SnowballStemmer\r\n",
        "def cleandesc(desc):\r\n",
        "    sent = desc\r\n",
        "    sent = \"\".join([x.lower() if x.isalpha()  else \" \" for x in sent])\r\n",
        "    Porter=SnowballStemmer('french')\r\n",
        "    sent = \" \".join([Porter.stem(x) if x.lower() not in stop_words  else \"\" for x in sent.split()])\r\n",
        "    sent = \" \".join(sent.split())\r\n",
        "    return sent\r\n",
        "start_time=time.time()\r\n",
        "\r\n",
        "#On prends la racine des mots pour le data frame df_test pour faire nos tests de comparaison\r\n",
        "\r\n",
        "df_test['title']= [cleandesc(x.title) for x in df_test.itertuples()]\r\n",
        "df_test['resume']= [cleandesc(x.resume) for x in df_test.itertuples()]\r\n",
        "df_test['query']= [cleandesc(x.query) for x in df_test.itertuples()]\r\n",
        "end_time=time.time()\r\n",
        "print(\"total time : {} mn\".format((end_time-start_time)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time : 0.00010286172231038412 mn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "srDwxa4YGRfG",
        "outputId": "24b8d98d-3e83-47ad-e71d-ee77b442f616"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>query</th>\n",
              "      <th>title</th>\n",
              "      <th>resume</th>\n",
              "      <th>mots</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machin learning and test or ador and futur and...</td>\n",
              "      <td>machin learning and the new innov paradigm</td>\n",
              "      <td>ador machin learning futur</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machin learning and innov</td>\n",
              "      <td>machin learning and the new innov paradigm</td>\n",
              "      <td>machin learning is very innov it</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ... mots\n",
              "0  https://graylinegroup.com/machine-learning-and...  ...     \n",
              "1  https://graylinegroup.com/machine-learning-and...  ...     \n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML-mKMxDK1qp"
      },
      "source": [
        "#On supprime les parenthèses de la requête et la met en minuscule pour le data frame qui servira à la sortie\r\n",
        "for i in range(len(df_new)):\r\n",
        "  df_new['query'][i]=df_new['query'][i].lower()\r\n",
        "  df_new['query'][i]=df_new['query'][i].replace(\"(\",\"\")\r\n",
        "  df_new['query'][i]=df_new['query'][i].replace(\")\",\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "OUc20D-hLb9J",
        "outputId": "6e53cbd4-d02c-419d-eb03-444b34f69309"
      },
      "source": [
        "df_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>query</th>\n",
              "      <th>title</th>\n",
              "      <th>resume</th>\n",
              "      <th>mots</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machine learning and test or adorer and du fut...</td>\n",
              "      <td>Machine learning and the new innovation paradigm</td>\n",
              "      <td>adorer le machine learning et du futur</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machine learning and innovation</td>\n",
              "      <td>Machine learning and the new innovation paradigm</td>\n",
              "      <td>Machine learning is very innovative. It's...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ... mots\n",
              "0  https://graylinegroup.com/machine-learning-and...  ...     \n",
              "1  https://graylinegroup.com/machine-learning-and...  ...     \n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFRpoVl9F0kB"
      },
      "source": [
        "def clear_out(df,df_n) :\r\n",
        "  for j in range (len(df)): # pour chaque ligne du df,\r\n",
        "    separator_or = list(df['query'][j].split(' or ')) #on stocke tous les couples de la requete dans une liste separator_or\r\n",
        "    sep_or= list(df_n['query'][j].split(' or '))\r\n",
        "    list_test=[] #liste pour stocker les mots en commun pour chaque ligne\r\n",
        "    for k in range (len(separator_or)): #pour chacun de ces couples,s\r\n",
        "      separator_and = list(separator_or[k].split(' and ')) #on stocke tous les mots du couple de la requete dans une liste separator_and\r\n",
        "      sep_and = list(sep_or[k].split(' and '))\r\n",
        "      for i in range (len(separator_and)): #pour tous les mots de la requete,\r\n",
        "        if (df['title'][j].find(separator_and[i]) != -1) : #on le cherche dans le titre, et si c'est présent...\r\n",
        "          list_test.append(sep_and[i])\r\n",
        "          print(sep_and[i])\r\n",
        "        if (df['resume'][j].find(separator_and[i]) != -1) : #ensuite, on le cherche dans le resumé, et si c'est présent...\r\n",
        "          list_test.append(sep_and[i]) #... on le met dans une liste\r\n",
        "          list_test = list(set(list_test))\r\n",
        "          print(sep_and[i])\r\n",
        "      str = ' '.join(list_test) #...\r\n",
        "    df_n['mots'][j]=list_test\r\n",
        "  return(df_n)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "38OnYz0zF3Nt",
        "outputId": "5fded85b-9aab-482b-a81f-12518aeabb29"
      },
      "source": [
        "dt = clear_out(df_test,df_new)\r\n",
        "dt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "machine learning\n",
            "machine learning\n",
            "adorer\n",
            "du futur\n",
            "adorer\n",
            "machine learning\n",
            "machine learning\n",
            "innovation\n",
            "innovation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>query</th>\n",
              "      <th>title</th>\n",
              "      <th>resume</th>\n",
              "      <th>mots</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machine learning and test or adorer and du fut...</td>\n",
              "      <td>Machine learning and the new innovation paradigm</td>\n",
              "      <td>adorer le machine learning et du futur</td>\n",
              "      <td>[machine learning, du futur, adorer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://graylinegroup.com/machine-learning-and...</td>\n",
              "      <td>machine learning and innovation</td>\n",
              "      <td>Machine learning and the new innovation paradigm</td>\n",
              "      <td>Machine learning is very innovative. It's...</td>\n",
              "      <td>[machine learning, innovation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ...                                  mots\n",
              "0  https://graylinegroup.com/machine-learning-and...  ...  [machine learning, du futur, adorer]\n",
              "1  https://graylinegroup.com/machine-learning-and...  ...        [machine learning, innovation]\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}