{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Wednesday 13th January 2021  \n",
    "\n",
    "# **POC Tendance des mots clefs**\n",
    "**Group 2 - Recherche de nouvelles sources**  \n",
    "*Projet Inter-Promo 2021 de la formation SID, Université Paul Sabatier, Toulouse*\n",
    "\n",
    "@authors : Yacine Seba, Amine Arouk, Nicolas Enjalbert Courrech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cadre d'une veille technologique, la récolte de document est la première étape importante de ce processus. Une façon de trouver ces articles est de faire une recherche textuelle avec un ensemble de mots clefs. \n",
    "Dans le cas de la veille technologique mise en place par Berger-Levrault proposer lors du projet inter-promo 2021 de la formation SID, deux lexiques ont été proposés, l'un portant sur l'innovation et l'autre sur les gammes de gestion. Ces lexiques composés d'environ 125 mots, nécessitent d'être combinés afin de donner une série de mots clefs répondant à la thématique jointe de l'innovation en gamme de gestion. Cette combinaison par produit cartésien donne un résultat d'environ 15625 combinaisons possibles. Il est donc très couteux d'utiliser l'ensemble des combinaisons des mots clefs au quotidien (pour la recherche d'article) ou hebdomadairement (pour l'identification des nouvelles sources pertinentes). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première solution proposés a été de retirer les combinaisons ne donnant pas de résultat aujourd'hui. Mais une question nous est vite apparue. En partant de l'idée qu'un mot clef n'est pas pertinent aujourd'hui et qu'il est supprimé de la liste des combinaisons, si demain il devient pertinent et que, dans le cas extrème, il exprime un sujet qui est clef dans l'innovation de gamme de gestion, est ce que les robots scrapeurs utilisant cette liste de combinaison pourront cibler ces articles thématiques ? La réponse est rapide : Non. \n",
    "\n",
    "Cette première solution n'est donc pas celle que nous devons aborder pour résoudre la problématique suivant : comment réduire la liste des combinaisons des mots-clefs ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième solution est de mettre en place une étude statistique sur les tendances des combinaisons des mots clefs. Cette solution permettra de donner un score de tendance à un couple de mots-clefs afin de définir ceux qui seront utilisés quotidiennement ou hebdomadairement. Notre méthode se déroule en plusieurs étapes qui seront détaillés le long de ce notebook . Nous nous baserons principalement sur deux métriques : L'occurence des couples dans les titres et résumés des liens ( dans les liens qui ressortent) ainsi que l'évolution de cette occurence au fil du temps. \n",
    "Une analyse statistiques de ces deux variables permettra de mettre en place une règle de décision pour sélectionner les couples de mots clefs à surveiller quotidiennent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SugazUp4Y41c"
   },
   "source": [
    "Ce document détaille les solutions mises en place. Notre solution se fait en quatre étapes. \n",
    "\n",
    "### 4 ETAPES :\n",
    "##### Etape 1 \n",
    "- Importation des librairies et des lexiques , création des liens contenenant les mots clés\n",
    "\n",
    "##### Etape 2\n",
    "- On crawl et on parse les données afin de récupérer les titres / résumés de chaque liens. \n",
    "Pour connaître les mots clefs les plus utilisés, nous utilisons une solution avec un moteur de recherche. Dans notre cas nous utilisons Google et testons un à un les combinaisons de mots clefs. Nous avons dans ce cas là deux résultats de recherche : le nombre de résultat de la recherche google et la liste des articles résultant. L'API que nous avons choisi dans le cadre du projet ne donne pas un nombre fixe de résultat de recherche car en faisant 2 fois consécutivement les recherches, le nombre n'était pas le même passant de 25 à 15000 par exemple. Par soucis de temps, nous avons donc mis en place le nombre d'article comptant les mots clefs dans leur titre ou résumé (voir étape 3) au lieu de mettre en place une autre API retournant un nombre plus fixe d'article. \n",
    "\n",
    "##### Etape 3\n",
    "- On analyse les titres et résumés afin de lister les mots du lexique qui y apparaissent (tokenization et suppression des stopwpords )\n",
    "\n",
    "##### Etape 4\n",
    "- On répertorie les couples de mots clés via un produit cartésien , on compte leurs occurences et l'évolution au fil du temps et on calcule le score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0IFINReMykU",
    "outputId": "30f515af-b07a-4d78-f690-189c42d028ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "########## Module import ##########\n",
    "\n",
    "# Files\n",
    "from google.colab import files\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Maths\n",
    "import random\n",
    "\n",
    "# Extraction\n",
    "import re\n",
    "\n",
    "# Scraping\n",
    "import scrapy\n",
    "#from scrapy import Selector\n",
    "from requests import get\n",
    "\n",
    "# Parsing\n",
    "from urllib.parse import urlencode\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Format\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "#import nltk functions and french stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer \n",
    "nltk.download('stopwords')\n",
    "stop_words=nltk.corpus.stopwords.words('french')\n",
    "\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aPkfpF6qijLL"
   },
   "outputs": [],
   "source": [
    "# Get the list of word combinations\n",
    "df = pd.read_json('listCouple.json', orient='index')\n",
    "df_t = df.T\n",
    "listCouple=df_t.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRAgI9ZZT6mY"
   },
   "source": [
    "**Transformer les fichiers txt des lexiques utilisés en listes**\n",
    "- Une liste pour le lexique d'innovation\n",
    "- Une liste pour le lexique de gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tb6dLjdc7Jwt",
    "outputId": "0c888673-69c8-4ce7-ec32-816cbb96ffee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collectivité territoriale', 'Administration', 'Mairie', 'Commune', \"Communauté d'agglomération\", 'Intercommunalités', 'Collectivités locales', 'Agglomération', 'Organisation territoriale', 'ville', 'élus', 'Finance', 'Finances publiques', 'Gestion financière', 'Performance publique', 'Analyse financière', 'évaluation des politiques publiques', 'Rapport de la Cour des comptes', 'CAP22', 'Comité action publique', 'Pilotage des dépenses', 'Flux financiers', 'Gestion comptable', 'Gestion de trésorerie', 'Budget', 'Processus achat', 'management opérationnel', 'aide à la décision', 'programmation pluriannuelle', 'PPI', 'PPF', 'trajectoire financière', 'AP', 'APCP', 'CP', 'AP/CP', 'autorisation de programme', 'crédit de paiement', 'gestion budgétaire', 'immobilisation', 'subvention', 'suivi financier et technique des marchés', 'SIGF', 'simulation', 'arbitrage', 'maquette budgétaire', 'bons de commandes', 'factures', 'liquidation', 'signature électronique', 'trésorerie', 'archivage électronique', 'télétransmission', 'GED', 'gestion électronique des documents', 'dette', 'comptabilité', 'chaîne comptable', 'factures électroniques', 'télétransmission', 'M14', 'M4X', 'M832', 'M22', 'dépenses', 'recettes', 'contrôles des saisies', 'dépassement de crédit', 'gestion de la comptabilité', 'gestion de la dette', \"gestion de l'inventaire\", 'emprunt', 'patrimoine comptable', 'validité réglementaire des saisies', 'éditions réglementaires', 'reporting', 'pilotage', 'marchés publics', \"pilotage de l'achat\", 'gestion des pièces financières', 'suivi administratif des consultations', 'dématérialisation', 'procédures de marchés publics', 'règlement de consultation', 'assistance fonctionnelle juridique', 'Ressources humaines', 'RH', 'SIRH', 'indicateurs clés', 'tableaux de bord', 'pilotage', 'masse salariale', 'Paie', 'Gestion de la paie', 'agents', 'fonctionnaire', 'personnel', 'managers', 'changement de poste', 'reclassement', 'évaluation', 'formation', 'retraites', 'capital humain', 'talents', 'Gestion Prévisionnelle des Emplois et des Compétences', 'GPEC', 'métiers', 'emplois', 'compétences', 'activités', 'risques', 'recrutement', 'données de gestion', 'workflow', 'carrière', 'conduite du changement', 'relations sociales', 'gestion administrative', 'contrôle de gestion', \"indicateurs d'exploitation\", 'anomalie', 'Référentiel patrimoine']\n",
      "['innovation', 'devops', 'interopérabilité', 'migration automatique', 'idm', 'mde', 'ingénierie dirigée par les modèles', 'ligne de produits', 'traçabilité', 'iot', 'ro', 'recherche opérationnelle', 'ml', 'machine learning', 'ia', 'intelligence artificielle', 'nlp', 'traitement automatique du langage', \"analyse d'image\", '3d', 'ihm', 'data-visualisation', \"visualisation d'informations\", 'visualisation de données', 'datavis', 'infovis', 'ar', 'vr', 'mr', 'réalité augmentée', 'réalité virtuelle', 'réalité mixte', 'robot', 'robotique', 'robotique sociale', 'sig', 'réseau', 'sécurité', 'si', \"systèmes d'information\", 'software', 'algorithmes génétiques', 'nsga', 'chatbot', 'adl', 'abstract description language', 'bd', 'base de données', 'data base', 'blockchain', 'material design', 'deep learning', \"reconnaissance d'image\", \"reconnaissance d'objets 3d\", 'edge analytics', 'big data', 'bigdata', 'big-data', 'rpa', 'hyperautomation', 'jumeau numérique', 'digital twin', 'immersive workspace', 'digitalops', 'augmented intelligence', 'wearable', 'multitouch', 'edge computing', 'cloud', 'data centers', '5g', 'explainable ai', 'edge ai', 'graphes de connaissances', 'knowledge graphs', 'ai paas', 'graph analytics', 'drone', 'virtual assistant', 'ontologie', 'ontologies', 'bmi', 'brain machine interface', 'bci', 'silver economy', 'smart city', 'ville numérique', 'université du futur', 'université 4.0', 'industrie 4.0', 'optimisation', 'système de recommandation', 'moteur de recommandation', 'user experience', 'ux', 'design thinking', 'web scraping', 'sustainability', 'développement durable', 'écologie', 'résilience', 'interfaces intelligentes', 'digitalisation', 'saas', 'microservices', '4.0', 'du futur', 'civictech', \"détection d'anomalies\", 'déploiement automatique', 'fusion de données', 'aide à la décision', 'low code', 'intergiciel', 'world sensing', 'Ordinateur quantique', 'cybersécurité', 'véhicule autonome', 'low-tech', 'do it yourself', 'makers', 'DIY', 'conjoncture', 'enjeux', 'prospective', 'nouvelle génération']\n"
     ]
    }
   ],
   "source": [
    "#retrieves words from different lexicons and puts them in a list\n",
    "\n",
    "with open('Lexique_Gammes_Gestion.txt') as img:\n",
    "    gestion = img.readlines()\n",
    "with open('Lexique_Innovation.txt') as img:\n",
    "    innovation = img.readlines()\n",
    "for i in range(len(gestion)):\n",
    "  gestion[i]=gestion[i][:-1]\n",
    "print(gestion)\n",
    "for i in range(len(innovation)):\n",
    "  innovation[i]=innovation[i][:-1]\n",
    "print(innovation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQi49x2WVsV7"
   },
   "source": [
    "- **Initialiser la clé de l'API**\n",
    "- **Initialiser les couples de mots à utiliser**\n",
    "- **Initialiser le nombre couple et de requête**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "mlFY_NNAeLLU"
   },
   "outputs": [],
   "source": [
    "########## Parameters to change ##########\n",
    "\n",
    "# API Key (created on Scraper API)\n",
    "API_KEY = '6e2f13665a14d50e37acdfc9636b4877'\n",
    "\n",
    "# Test on a few couples\n",
    "p_listCouple = listCouple\n",
    "# Number of couples\n",
    "p_length = 1\n",
    "# Number of requests\n",
    "p_requestNumber = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "C1qWQ_p2J03N"
   },
   "outputs": [],
   "source": [
    "#list of sites we don't want to scrap \n",
    "banned_links = ['www.linkedin.com','fr.linkedin.com','www.linguee.com','www.researchgate.net','docplayer.org','docplayer.net','docplayer.fr','books.google.com','books.google.fr','www.cairn.info','www.pinterest.com','www.pinterest.fr','fr.indeed.com','www.indeed.fr','www.indeed.com','www.facebook.com','viadeo.journaldunet.com','fr.wikipedia.org','www.senat.fr','www.amazon.com','www.amazon.fr','www.youtube.com','twitter.com','www.slideshare.net','fr.slideshare.net','www.calameo.com','www.talent.com','fr.talent.com','issuu.com','www.aijobs.tech','www.economie.gouv.fr','theses.fr','www.theses.fr','hal.archives-ouvertes.fr','fr.scribd.com','www.scribd.com','www.legifrance.gouv.fr','www2.assemblee-nationale.fr','www.assemblee-nationale.fr','www2.assemblee-nationale.fr','www.ccomptes.fr','www.vie-publique.fr','www.banquedesterritoires.fr','core.ac.uk','www.cnfpt.fr','www.malt.fr','www.malt.com','link.springer.com','www.sciencedirect.com','slideplayer.fr','slideplayer.org','slideplayer.com']\n",
    "\n",
    "#stopword=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#this section is detailed in audrey's notebook \n",
    "def ban_links(links_banned = banned_links) :\n",
    "  a=' '\n",
    "  for i in links_banned :\n",
    "    a += '-inurl:'+i+' '\n",
    "\n",
    "  return a[:-1]\n",
    "\n",
    "\n",
    "def remove_stopwords(tokenzed_list):\n",
    "    text=[word for word in tokenzed_list if word not in stop_words]\n",
    "    return text\n",
    "    \n",
    "def tokenize(text):\n",
    "    \n",
    "    tokens = re.split('\\s|[\\']', text)\n",
    "    #W+ means a word character or - can go there\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def around_query(lexique) :\n",
    "  liste = lexique.copy()\n",
    "  liste = [tokenize(i) for i in liste]\n",
    "  liste = [remove_stopwords(i) for i in liste]\n",
    "  for i in range(len(liste)) :\n",
    "    if len(liste[i]) == 1 :\n",
    "      liste[i] = liste[i][0]\n",
    "    else :\n",
    "      texte =  liste[i][0] \n",
    "      for j in range(1,len(liste[i])) :\n",
    "        texte += ' AROUND(2) ' + liste[i][j]\n",
    "      liste[i] = texte\n",
    "  return liste\n",
    "\n",
    "  \n",
    "lexique_gestion_tokenize = around_query(gestion)\n",
    "lexique_innovation_tokenize = around_query(innovation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk_3GRyvVnKp"
   },
   "source": [
    "**Création des fonctions qui vont nous permettre de créer notre crawler Google en utilisant la liste de couple de mots initialisée en préalable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "uuWfD8aGJCUg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_google_url(query):\n",
    "    \"\"\" \n",
    "    Allows you to create a Google URL from a keyword\n",
    "\n",
    "    Parameter :\n",
    "        query : keyword to enter in the search bar\n",
    "    \n",
    "    Out :\n",
    "        google_url : google URL created from the keyword\n",
    "    \"\"\"\n",
    "    # num = number of results to be scraped\n",
    "    google_dict = {'q': query, 'num': 20,}\n",
    "    google_url = 'http://www.google.com/search?' + urlencode(google_dict)\n",
    "    return google_url\n",
    "\n",
    "def combAND(couple):\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        couple: a list of 2 Strings\n",
    "    Out :\n",
    "        list : a combination of the 2 members of a couple with AND between them\n",
    "    \"\"\"\n",
    "\n",
    "    return str(couple[0])+' '+'AND'+' '+str(couple[1])\n",
    "\n",
    "def listToAND(listCouple):\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        listCouple: a list of couple\n",
    "\n",
    "    Out :\n",
    "        list : a list of the combination of the couple of listCouple\n",
    "    \"\"\"\n",
    "\n",
    "    #we use combAND\n",
    "    return [combAND(i) for i in listCouple]\n",
    "\n",
    "\n",
    "def combOR(tuple):\n",
    "    \"\"\"Documentation\n",
    "\n",
    "    Parameters:\n",
    "        tuple: a list of String\n",
    "\n",
    "    Out :\n",
    "        final : a combination of the members of the tuple with OR between them and framed with ()\n",
    "    \"\"\"\n",
    "\n",
    "    #first step : initialisation of final\n",
    "    final='('+str(tuple[0])+')'\n",
    "    #second step : adding the rest of the tuple\n",
    "    for i in range(1,len(tuple)):\n",
    "        final=final+'|'+'('+tuple[i]+')'\n",
    "    return final\n",
    "\n",
    "#applying the previous function to a list of tuple\n",
    "def listToOR(listTuple):\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        listTuple: a list of tuples\n",
    "\n",
    "    Out :\n",
    "        list : a list of the combination of the tuple of listTuple\n",
    "    \"\"\"\n",
    "\n",
    "    #we use combOR\n",
    "    return [combOR(i) for i in listTuple]\n",
    "\n",
    "#making a list of random tuples\n",
    "def listComb(listAND,numbT=2,iteration=int(1000)): #we have to limit the number of request, by default 1000, and we make couples (2)\n",
    "    \"\"\"Documentation\n",
    "\n",
    "    Parameters:\n",
    "        listAND: a list Strings with AND\n",
    "        numbT : the length of the tuple we want to create\n",
    "        iteration : the maximum number of combination we want to create\n",
    "\n",
    "    Out :\n",
    "        finalList : a list of the combination of the tuple of listTuple\n",
    "    \"\"\"\n",
    "\n",
    "    finalList=[]\n",
    "    i=0\n",
    "    #Step 1 : we loop until we have enough tuples or the list is empty\n",
    "    while ((len(listAND)>=numbT) and (i<iteration)):\n",
    "        i+=1\n",
    "        #Step 2 : at each loop, we take some random elements of listAND and create a tuple with them\n",
    "        listRand=random.sample(listAND,numbT)\n",
    "        #Step 3 : we remove the elements from listAND\n",
    "        for j in listRand :\n",
    "            listAND.remove(j)\n",
    "        #Step 4 :we add the tuple we created to our finalList\n",
    "        finalList.append(listRand)\n",
    "    return finalList\n",
    "\n",
    "#function that allows to add a \"limit date\" parameter in the link\n",
    "def link_sub_month(link, nbmonths):\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    nbdays=nbmonths*31\n",
    "\n",
    "    days_to_substract = datetime.timedelta(days=nbdays)\n",
    "\n",
    "    date = today - days_to_substract\n",
    "    #limit date\n",
    "    \n",
    "    jour=str(date.day)\n",
    "    mois=str(date.month)\n",
    "    annee=str(date.year)\n",
    "    \n",
    "    link = link+\"&source=lnt&tbs=cdr%3A1%2Ccd_min%3A\"+mois+\"%2F\"+jour+\"%2F\"+annee+\"%2Ccd_max%3A&tbm=\"\n",
    "    return link\n",
    "\n",
    "def get_url(url):\n",
    "    \"\"\" \n",
    "    Creation of the URL that will allow the legal scraping of Google results (use of the API key). \n",
    "    This URL is equivalent to a Google search.\n",
    "\n",
    "    Parameter :\n",
    "        url : google URL created from the keyword\n",
    "    \n",
    "    Out :\n",
    "        proxy_url : URLs built using the API\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {'api_key': API_KEY, 'url': url, 'autoparse': 'true', 'country_code': 'fr', 'pws': 0}\n",
    "    proxy_url = 'http://api.scraperapi.com/?' + urlencode(payload)\n",
    "    date_url = proxy_url + link_sub_month(proxy_url, 6)\n",
    "    return proxy_url\n",
    "\n",
    "class GoogleSpider(scrapy.Spider):\n",
    "    \"\"\" \n",
    "    This class lists functions for scraping Google results from a list of keywords\n",
    "    \"\"\"\n",
    "\n",
    "    # GoogleSpider class name\n",
    "    name = 'google'\n",
    "    # Name of the site to be scraped\n",
    "    allowed_domains = ['www.google.com']\n",
    "    # Settings\n",
    "    custom_settings = {\n",
    "                        # Criticality level at which the log is displayed\n",
    "                        'LOG_LEVEL': 'INFO', \n",
    "                        # Maximum number of simultaneous requests \n",
    "                        'CONCURRENT_REQUESTS_PER_DOMAIN': 1, \n",
    "                        # Maximum number of retries to be made if the query fails\n",
    "                        'RETRY_TIMES': 0}\n",
    "\n",
    "    def start_requests(self, listCouple, length, requestNumber,banned_links=banned_links):\n",
    "        #Initialisation of DataFrame\n",
    "        df = pd.DataFrame(columns=['URL','Query'])\n",
    "        #Adding quotes\n",
    "        #listCouple = listExpression(listCouple)\n",
    "        #Format changeover \n",
    "        lWork=listToAND(listCouple)\n",
    "        #Selection of queries \n",
    "        lWork=listComb(lWork,numbT=length, iteration=requestNumber)\n",
    "        #We change the format of Keywords\n",
    "        lWork=listToOR(lWork)\n",
    "\n",
    "        lURL=[]\n",
    "        #We loop the keywords to generate the queries \n",
    "        #for query in ['emprunt écologie'] :\n",
    "        for query in lWork:\n",
    "            \n",
    "            url = create_google_url(query+ban_links(banned_links[:10])) #Trier\n",
    "            lURL.append(str(scrapy.Request(get_url(url), callback=self.parse, meta={'pos': 0}))[5:-1])\n",
    "        # url = create_google_url('innovation ville')\n",
    "        # lURL.append(str(scrapy.Request(get_url(url), callback=self.parse, meta={'pos': 0}))[5:-1])\n",
    "        #column generation\n",
    "        df['Query'] = lWork\n",
    "        df['URL'] = lURL\n",
    "\n",
    "        yield df\n",
    "\n",
    "    def parse(self, response):\n",
    "        di = json.loads(response.text)\n",
    "        pos = response.meta['pos']\n",
    "        dt = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        for result in di['organic_results']:\n",
    "            title = result['title']\n",
    "            snippet = result['snippet']\n",
    "            link = result['link']\n",
    "            item = {'title': title, 'snippet': snippet, 'link': link, 'position': pos, 'date': dt}\n",
    "            pos += 1\n",
    "            yield item\n",
    "        next_page = di['pagination']['nextPageUrl']\n",
    "        if next_page:\n",
    "            yield print(scrapy.Request(get_url(next_page), callback=self.parse, meta={'pos': pos}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9NegZ3kVbSx"
   },
   "source": [
    "**Génération du lien de scraper API contenant les mots clés **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzVqLYjYwxFB",
    "outputId": "99cf2b80-a0b8-4639-d12b-11f1b48d0417"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['http://api.scraperapi.com/?api_key=6e2f13665a14d50e37acdfc9636b4877&url=http%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3D%2528%2522Finance%2522%2BAND%2B%2522cybers%25C3%25A9curit%25C3%25A9%2522%2529%2B-inurl%253Awww.linkedin.com%2B-inurl%253Afr.linkedin.com%2B-inurl%253Awww.linguee.com%2B-inurl%253Awww.researchgate.net%2B-inurl%253Adocplayer.org%2B-inurl%253Adocplayer.net%2B-inurl%253Adocplayer.fr%2B-inurl%253Abooks.google.com%2B-inurl%253Abooks.google.fr%2B-inurl%253Awww.cairn.info%26num%3D20&autoparse=true&country_code=fr&pws=0',\n",
       "       'http://api.scraperapi.com/?api_key=6e2f13665a14d50e37acdfc9636b4877&url=http%3A%2F%2Fwww.google.com%2Fsearch%3Fq%3D%2528%2522pilotage%2Bde%2Bl%2527achat%2522%2BAND%2B%2522augmented%2Bintelligence%2522%2529%2B-inurl%253Awww.linkedin.com%2B-inurl%253Afr.linkedin.com%2B-inurl%253Awww.linguee.com%2B-inurl%253Awww.researchgate.net%2B-inurl%253Adocplayer.org%2B-inurl%253Adocplayer.net%2B-inurl%253Adocplayer.fr%2B-inurl%253Abooks.google.com%2B-inurl%253Abooks.google.fr%2B-inurl%253Awww.cairn.info%26num%3D20&autoparse=true&country_code=fr&pws=0'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start building URLs\n",
    "if __name__ == '__main__':\n",
    "    df_result = list(GoogleSpider().start_requests(listCouple = p_listCouple,length=p_length,requestNumber=p_requestNumber))[0]\n",
    "df_result['URL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DdiLFrla3LW",
    "outputId": "2f119310-0211-447f-f852-6c34f4380587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:59:33\n"
     ]
    }
   ],
   "source": [
    "# Crawling start time\n",
    "print((datetime.datetime.now()++datetime.timedelta(hours=1)).strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyuklrWNX6Px"
   },
   "source": [
    "#Transition entre la première et la deuxième étape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l8Et3fTVQAj"
   },
   "source": [
    "**Crawler les liens API générés ci-dessus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1lC6rJuhP3XE"
   },
   "outputs": [],
   "source": [
    "list_source = []\n",
    "i = 0\n",
    "\n",
    "for index, row in df_result.iterrows():\n",
    "    link = row['URL']\n",
    "    query = row['Query']\n",
    "    # 1 minute break to avoid API overloading\n",
    "    time.sleep(60)\n",
    "    # URL scraping\n",
    "    response = get(link)\n",
    "    # Test if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Addition of the scraped google results and the corresponding query\n",
    "        list_source.append([response.text, query])\n",
    "\n",
    "        i+=1\n",
    "        # Saving the results every 20 queries\n",
    "        if (i%20==0):\n",
    "            with open('etape'+str(i)+'.json', 'w') as jsonfile:\n",
    "                json.dump(list_source, jsonfile)\n",
    "            files.download('etape'+str(i)+'.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EodfRZRdsk1N",
    "outputId": "10ce6afd-1138-4d58-a181-e1dac1fe7980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['{\"search_information\":{\"total_results\":113,\"time_taken_displayed\":7.14,\"query_displayed\":\"(\\\\\"pilotage de l\\'achat\\\\\" AND \\\\\"augmented intelligence\\\\\") -inurl:www.linkedin.com -inurl:fr.linkedin.com -inurl:www.linguee.com -inurl:www.researchgate.net -inurl:docplayer.org -inurl:docplayer.net -inurl:docplayer.fr -inurl:books.google.com -inurl:books.google.fr -inurl:www.cairn.info\"},\"ads\":[],\"knowledge_graph\":{\"title\":\"\",\"description\":\"\",\"source\":{\"name\":\"\"},\"related\":[],\"related_link\":null,\"social_media\":[],\"see_more_about\":[]},\"related_questions\":[],\"answer_box\":null,\"organic_results\":[{\"position\":1,\"title\":\"La révolution de l\\'intelligence - Préparer l\\'avenir de ... - Deloitte\",\"snippet\":\"apporté son lot de richesse et d\\'innovation; elle est à l\\'origine de ... automatiquement les achats au compte des ... Analyste de transport à pilotage ... ://dupress.deloitte.com/dup-us-en/deloitte-review/issue-20/augmented-intelligence-human-.\",\"link\":\"https://www2.deloitte.com/content/dam/Deloitte/ca/Documents/human-capital/ca-fr-hc-IntelligenceRev-POV-Oct25-AODA.pdf\",\"date\":\"\",\"displayed_link\":\"www2.deloitte.com › Deloitte › Documents › human-capital\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":2,\"title\":\"Les usages de l\\'intelligence artificielle - Olivier Ezratty\",\"snippet\":\"Nov 18, 2019 — de l\\'innovation technologique vue sous les angles scientifiques, ... achats, les fake news) et une sérieuse évolution des parties sur l\\'aviation, sur la distribution et sur ... 11 Voir Why AI Should Rightfully Mean Augmented Intelligence, Not ... du pilotage de réseaux de neurones à bas niveau et permettent par\\xa0...\",\"link\":\"https://www.oezratty.net/wordpress/wp-content/themes/Ezratty5/forcedownload.php?file=/Files/Publications/Usages%20intelligence%20artificielle%202019%20Olivier%20Ezratty.pdf\",\"date\":\"Nov 18, 2019 —\",\"displayed_link\":\"www.oezratty.net › themes › Ezratty5 › forcedownload\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":3,\"title\":\"Banques / Assurances - l\\'EBG\",\"snippet\":\"2// Banques / Assurances : Comment la data lead la transformation de ce secteur ? Le secteur de la ... Augmented Intelligence : est-ce la solution pour faciliter l\\'usage de la data ? INTroDuCTIoN ... semestre une activité de vente indirecte via le développement du ... d\\'un dispositif de pilotage (ex : dashboard), ou dans une\\xa0...\",\"link\":\"https://www.ebg.net/publications/pdf/100063.pdf\",\"date\":\"\",\"displayed_link\":\"www.ebg.net › publications › pdf\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:q7p5j2Yxqj8J:https://www.ebg.net/publications/pdf/100063.pdf+&cd=3&hl=en&ct=clnk&gl=fr\"},{\"position\":4,\"title\":\"Définitions RH - Transformation digitale et Future of work\",\"snippet\":\"Toutes les définitions RH du Future of Work sur une seule page ! ... L\\'Analytique RH (ou HR Analytics) est une méthode qui consiste à identifier et exploiter la masse ... éducation, construction, hôtellerie, industrie, agriculture, santé, vente, etc. ... L\\'intelligence augmentée (ou augmented intelligence en anglais) est une façon\\xa0...\",\"link\":\"https://www.people-doc.fr/transformation-digitale-definition\",\"date\":\"\",\"displayed_link\":\"www.people-doc.fr › transformation-...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:cmHX7HE3Im4J:https://www.people-doc.fr/transformation-digitale-definition+&cd=4&hl=en&ct=clnk&gl=fr\"},{\"position\":5,\"title\":\"Données médicales - European Strategy and Policy Analysis ...\",\"snippet\":\"B. Poursuivre la consolidation de l\\'infrastructure de données médicales et en extraire toute la ... Usages multi-niveaux dans le pilotage médico-administratif du système de soins 23. Irruptions des ... leurs habitudes d\\'achat ou de leur comportement en ligne. Pour l\\'instant les ... Medical Augmented Intelligence. La réalité\\xa0...\",\"link\":\"https://espas.secure.europarl.europa.eu/orbis/sites/default/files/generated/document/en/Donn%C3%A9es%20m%C3%A9dicales.pdf\",\"date\":\"\",\"displayed_link\":\"espas.secure.europarl.europa.eu › generated › document\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":6,\"title\":\"Emplois : Chef De Projet - janvier 2021 - AI Jobs france\",\"snippet\":\"A la recherche d\\'un emploi : Chef De Projet ? Il y en a 14796 disponibles dans des entreprises telles que Systran, Lca Mediterranee, Metro.\",\"link\":\"https://www.aijobs.tech/fr/j/t/emplois-chef-de-projet/\",\"date\":\"\",\"displayed_link\":\"www.aijobs.tech › emplois-chef-de-projet\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:DNrolr1jRZEJ:https://www.aijobs.tech/fr/j/t/emplois-chef-de-projet/+&cd=6&hl=en&ct=clnk&gl=fr\"},{\"position\":7,\"title\":\"Emplois : Business Intelligence Manager - janvier ... - Indeed\",\"snippet\":\"Vous êtes à la recherche d\\'un emploi : Business Intelligence Manager ? Il y en a 594 disponibles sur Indeed.com, le plus grand site d\\'emploi mondial. ... Outils de Business Intelligence – Pilotage de laboratoire. Pour soutenir notre ... Dans l\\'ensemble, à quel point trouvez-vous ces offres d\\'emploi pertinentes ? Pas du tout.\",\"link\":\"https://fr.indeed.com/Emplois-Business-Intelligence-Manager\",\"date\":\"\",\"displayed_link\":\"fr.indeed.com › Emplois-Business-In...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:NeXXNXWy40UJ:https://fr.indeed.com/Emplois-Business-Intelligence-Manager+&cd=7&hl=en&ct=clnk&gl=fr\"},{\"position\":8,\"title\":\"Trouver un partenaire - Tableau Software\",\"snippet\":\"DATA SEMANTICS has the ability to work with Multiple and Complex Data Platforms- enabling the quick enterprise wide implementation of Tableau. They also\\xa0...\",\"link\":\"https://www.tableau.com/fr-fr/partners/search?page=4&region=All\",\"date\":\"\",\"displayed_link\":\"www.tableau.com › fr-fr › partners › search\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:layB7yPWqwkJ:https://www.tableau.com/fr-fr/partners/search%3Fpage%3D4%26region%3DAll+&cd=8&hl=en&ct=clnk&gl=fr\"},{\"position\":9,\"title\":\"Trouver un partenaire | Tableau Software\",\"snippet\":\"DECIDEOM est expert dans le domaine de l\\'informatique décisionnelle. Plus qu\\'une société de services, nous agissons comme un véritable partenaire, sur le\\xa0...\",\"link\":\"https://www.tableau.com/fr-fr/partners/alliance?certifications=server_certified&country=AL&partnership_level=All&region=All&page=10\",\"date\":\"\",\"displayed_link\":\"www.tableau.com › fr-fr › partners › alliance\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":10,\"title\":\"20180214_numerique_livret_v2_sr_rc_ca_v3_1_.pdf - Cgt 44\",\"snippet\":\"18. V. DE L\\'UTILITÉ DU SYNDICALISME CGT DANS LA SOCIÉTÉ NUMÉRISÉE ... ne met pas fin à l\\'affrontement capital/travail. Alain Supiot (La gouvernance par les ... À titre d\\'exemple, l\\'achat en avance d\\'un billet de ... l\\'objectif est la mise en place d\\'un pilotage ... mentée (augmented intelligence : coo- pération entre\\xa0...\",\"link\":\"http://lacgt44.fr/IMG/pdf/20180214_numerique_livret_v2_sr_rc_ca_v3_1_.pdf\",\"date\":\"\",\"displayed_link\":\"lacgt44.fr › IMG › 20180214_numerique_livret_v2_sr_r...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":11,\"title\":\"Communiqués de presse - Sofimac Investment Managers\",\"snippet\":\"Bruno Le Maire, ministre de l\\'Economie et des Finances, en lien avec la ... Le 23 Janvier 2020 – Snowleader, le site de vente en ligne français de ... La société spécialisée dans le pilotage de la performance publicitaire lève 1 ... Cosmo Tech Raises $3M to Deliver Augmented Intelligence Technologies to Global Market.\",\"link\":\"https://www.sofimac-im.com/communiques-de-presse-2/\",\"date\":\"\",\"displayed_link\":\"www.sofimac-im.com › communiqu...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:EW258ZpaxmQJ:https://www.sofimac-im.com/communiques-de-presse-2/+&cd=11&hl=en&ct=clnk&gl=fr\"},{\"position\":12,\"title\":\"Articles AFIB RSNA 2017 V1 - HUG\",\"snippet\":\"Le rôle de l\\'imagerie est central tant au niveau du diagnostic, par les progrès continus ... PHILIPS partage un argument de vente : IQon est « la réponse aux 3 ... disponibles pour proposer des outils pédagogiques avancés : cockpit de pilotage pour ... projet global, intitulé Augmented Intelligence, qui proposera à terme des\\xa0...\",\"link\":\"https://www.hug-ge.ch/sites/interhug/files/structures/service_dingenierie_biomedicale/etat_de_lart_en_imagerie_medicale_-_rsna_2017_-_radiologie_numerique.pdf\",\"date\":\"\",\"displayed_link\":\"www.hug-ge.ch › files › service_dingenierie_biomedicale\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:g6_K8BvaEmoJ:https://www.hug-ge.ch/sites/interhug/files/structures/service_dingenierie_biomedicale/etat_de_lart_en_imagerie_medicale_-_rsna_2017_-_radiologie_numerique.pdf+&cd=12&hl=en&ct=clnk&gl=fr\"},{\"position\":13,\"title\":\"Michelle ALONDA - Technical Marketing Engineer - Cosmo ...\",\"snippet\":\"Je suis Alonda Michelle, manager en charge du Sales Enablement Chez Cosmo Tech. ... faire du services après son achat et cela à fait intervenir des relations B2B et B2C. ... d\\'analyse stratégique ou encore de pilotage de projets énergétiques. Le marketing et le management de l\\'énergie nécessitent de s\\'appuyer sur de\\xa0...\",\"link\":\"https://ug.linkedin.com/pub/michelle-alonda/5a/b36/b72?trk=biz_employee_pub\",\"date\":\"\",\"displayed_link\":\"ug.linkedin.com › pub › michelle-alo...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":14,\"title\":\"Les mercredis du Big Data | Webinars du congrès Big Data ...\",\"snippet\":\"Participez aux webinars Big Data Paris, tous les mercredis après-midi à partir de ... 8 webinars dédiés aux solutions et projets qui font l\\'actualité du Big Data.\",\"link\":\"https://www.bigdataparis.com/2019/webinars/\",\"date\":\"\",\"displayed_link\":\"www.bigdataparis.com › webinars\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:r_A5Nk1T57MJ:https://www.bigdataparis.com/2019/webinars/+&cd=14&hl=en&ct=clnk&gl=fr\"},{\"position\":15,\"title\":\"NICE : 18ème Festival d&rsquo;Opérette et comédie musicale de ...\",\"snippet\":\"\",\"link\":\"http://www.presseagence.fr/lettre-economique-politique-paca/2019/10/page/12/?print=pdf-search\",\"date\":\"\",\"displayed_link\":\"www.presseagence.fr › 2019/10 › page\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"http://webcache.googleusercontent.com/search?q=cache:TnCGab5wpqoJ:www.presseagence.fr/lettre-economique-politique-paca/2019/10/page/12/%3Fprint%3Dpdf-search+&cd=15&hl=en&ct=clnk&gl=fr\"},{\"position\":16,\"title\":\"docteur de l\\'université de bordeaux - Thèses\",\"snippet\":\"L\\'avancée de l\\'étude de la cognition collective, cœur du travail collaboratif ... Cette simulation de pilotage de véhicule d\\'exploration de surface. (rover) a été ... unités. Il revient donc au joueur de gérer ses propres dépenses et achats ; ... computing and augmented intelligence in man-system integration: Impact on C2 HQ key.\",\"link\":\"https://www.theses.fr/2020BORD0227.pdf\",\"date\":\"\",\"displayed_link\":\"www.theses.fr › ...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]}},{\"position\":17,\"title\":\"Éditorial - AUSIM MAROC\",\"snippet\":\"Oct 26, 2018 — Lettre d\\'information pour les professionnels de l\\'IT au Maroc ... d\\'investissement créé pour acheter des équipes sportives ... Assurer le pilotage de projets innovants en mode ... think about AI as augmented intelligence. AI and\\xa0...\",\"link\":\"http://www.ausimaroc.com/wp-content/uploads/2018/09/Ausinews-N11.pdf\",\"date\":\"Oct 26, 2018 —\",\"displayed_link\":\"www.ausimaroc.com › 2018/09 › Ausinews-N11\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"http://webcache.googleusercontent.com/search?q=cache:MdPpDnOAfdMJ:www.ausimaroc.com/wp-content/uploads/2018/09/Ausinews-N11.pdf+&cd=17&hl=en&ct=clnk&gl=fr\"},{\"position\":18,\"title\":\"Un design centré sur l\\'utilisateur - Zumtobel\",\"snippet\":\"signifie pour l\\'aménagement des espaces de vente. Le magasin ... pement. Le nouveau mot d\\'ordre est « augmented intelligence ». ENTRETIEN. 20 ... durablement modifier l\\'univers du pilotage de l\\'éclairage des bâtiments. Dès le départ, des\\xa0...\",\"link\":\"https://www.zumtobel.com/PDB/Ressource/teaser/fr/Lightlife_09_2014.pdf\",\"date\":\"\",\"displayed_link\":\"www.zumtobel.com › PDB › teaser › Lightlife_09_2014\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:A5JRu_unGBIJ:https://www.zumtobel.com/PDB/Ressource/teaser/fr/Lightlife_09_2014.pdf+&cd=18&hl=en&ct=clnk&gl=fr\",\"related_pages_link\":\"https://www.google.com/search?gl=FR&q=related:https://www.zumtobel.com/PDB/Ressource/teaser/fr/Lightlife_09_2014.pdf+(pilotage+de+lachat+AND+augmented+intelligence)+-inurl:www.linkedin.com+-inurl:fr.linkedin.com+-inurl:www.linguee.com+-inurl:www.researchgate.net+-inurl:docplayer.org+-inurl:docplayer.net+-inurl:docplayer.fr+-inurl:books.google.com+-inurl:books.google.fr+-inurl:www.cairn.info&sa=X&ved=2ahUKEwjlr431wp7uAhXoFqYKHWnmCqIQHzARegQIEBAI\"},{\"position\":19,\"title\":\"Rapport annuel TIBCO - Exercice 2015 - SlideShare\",\"snippet\":\"Dec 20, 2016 — Bonjour Voici le rapport annuel 2015 de TIBCO des chiffres, des vidéos, ... de services Desk 24/7 Pilotage Planification Expertise Supervision et niveau 2 ... au ﬁl de l\\'eau Solutions techniques et sécurité Conseil et vente de ... Tibco Augmented Intelligence - Analytics, IoT, Big Data, Streaming 20161025.\",\"link\":\"https://www.slideshare.net/pascaloup/rapport-annuel-tibco-exercice-2015\",\"date\":\"Dec 20, 2016 —\",\"displayed_link\":\"www.slideshare.net › pascaloup › rap...\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:bweVveSK8BYJ:https://www.slideshare.net/pascaloup/rapport-annuel-tibco-exercice-2015+&cd=19&hl=en&ct=clnk&gl=fr\"},{\"position\":20,\"title\":\"skema business school - Choose France! Education & Career ...\",\"snippet\":\"values and DNA of our research, our programmes and our organisation. SKEMA ... SKEMA Global Lab in Augmented Intelligence ... 30 % de l\\'effectif total du MS, les ... et de leadership en gestion des opérations, supply chain et pilotage de la ... Manager de la chaîne logistique et achats : les connaissances acquises, les.\",\"link\":\"https://www.studyinfrance.sg/wp-content/uploads/2020/10/3.-Brochure_mastersdegree_EN-SKEMA.pdf\",\"date\":\"\",\"displayed_link\":\"www.studyinfrance.sg › wp-content › uploads › 2020/10\",\"thumbnail\":null,\"sitelinks\":{\"inline\":[],\"block\":[]},\"cached_page_link\":\"https://webcache.googleusercontent.com/search?q=cache:caMQE7IAzewJ:https://www.studyinfrance.sg/wp-content/uploads/2020/10/3.-Brochure_mastersdegree_EN-SKEMA.pdf+&cd=20&hl=en&ct=clnk&gl=fr\"}],\"related_searches\":[],\"pagination\":{\"pagesCount\":2,\"currentPage\":1,\"nextPageUrl\":\"https://www.google.com/search?q=(pilotage+de+lachat+AND+augmented+intelligence)+-inurl:www.linkedin.com+-inurl:fr.linkedin.com+-inurl:www.linguee.com+-inurl:www.researchgate.net+-inurl:docplayer.org+-inurl:docplayer.net+-inurl:docplayer.fr+-inurl:books.google.com+-inurl:books.google.fr+-inurl:www.cairn.info&num=20&gl=FR&ei=0dgBYKWDIeitmAXpzKuQCg&start=20&sa=N&ved=2ahUKEwjlr431wp7uAhXoFqYKHWnmCqIQ8tMDegQIChA_\",\"prevPageUrl\":null,\"pages\":[{\"page\":2,\"url\":\"https://www.google.com/search?q=(pilotage+de+lachat+AND+augmented+intelligence)+-inurl:www.linkedin.com+-inurl:fr.linkedin.com+-inurl:www.linguee.com+-inurl:www.researchgate.net+-inurl:docplayer.org+-inurl:docplayer.net+-inurl:docplayer.fr+-inurl:books.google.com+-inurl:books.google.fr+-inurl:www.cairn.info&num=20&gl=FR&ei=0dgBYKWDIeitmAXpzKuQCg&start=20&sa=N&ved=2ahUKEwjlr431wp7uAhXoFqYKHWnmCqIQ8tMDegQIChA_\"}]}}',\n",
       "  '(\"pilotage de l\\'achat\" AND \"augmented intelligence\")']]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZfKTwZ7bFKq",
    "outputId": "a43f692e-d3d3-4713-cc96-960f6ee79791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:03:05\n"
     ]
    }
   ],
   "source": [
    "# Crawling end time\n",
    "print((datetime.datetime.now()++datetime.timedelta(hours=1)).strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAm3nEE-TjEo"
   },
   "source": [
    "**Extraction des informations qu'on veut garder :**\n",
    "- Liens des articles\n",
    "- Titres des articles\n",
    "- Résumés des articles\n",
    "- Positions des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "wXth4gujOFda",
    "outputId": "a9895206-6844-4999-9dae-f8f9f24e2b9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Query</th>\n",
       "      <th>title</th>\n",
       "      <th>resume</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www2.deloitte.com/content/dam/Deloitte...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>La révolution de l'intelligence - Préparer l'a...</td>\n",
       "      <td>apporté son lot de richesse et d'innovation; e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.oezratty.net/wordpress/wp-content/...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Les usages de l'intelligence artificielle - Ol...</td>\n",
       "      <td>Nov 18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ebg.net/publications/pdf/100063.pdf</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Banques / Assurances - l'EBG</td>\n",
       "      <td>2// Banques / Assurances : Comment la data lea...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.people-doc.fr/transformation-digit...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Définitions RH - Transformation digitale et Fu...</td>\n",
       "      <td>Toutes les définitions RH du Future of Work su...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://espas.secure.europarl.europa.eu/orbis/...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Données médicales - European Strategy and Poli...</td>\n",
       "      <td>B. Poursuivre la consolidation de l'infrastruc...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.aijobs.tech/fr/j/t/emplois-chef-de...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Emplois : Chef De Projet - janvier 2021 - AI J...</td>\n",
       "      <td>A la recherche d'un emploi : Chef De Projet ? ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://fr.indeed.com/Emplois-Business-Intelli...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Emplois : Business Intelligence Manager - janv...</td>\n",
       "      <td>Vous êtes à la recherche d'un emploi : Busines...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.tableau.com/fr-fr/partners/search?...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Trouver un partenaire - Tableau Software</td>\n",
       "      <td>DATA SEMANTICS has the ability to work with Mu...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.tableau.com/fr-fr/partners/allianc...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Trouver un partenaire | Tableau Software</td>\n",
       "      <td>DECIDEOM est expert dans le domaine de l'infor...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://lacgt44.fr/IMG/pdf/20180214_numerique_l...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>20180214_numerique_livret_v2_sr_rc_ca_v3_1_.pd...</td>\n",
       "      <td>18. V. DE L'UTILITÉ DU SYNDICALISME CGT DANS L...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.sofimac-im.com/communiques-de-pres...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Communiqués de presse - Sofimac Investment Man...</td>\n",
       "      <td>Bruno Le Maire</td>\n",
       "      <td>11</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.hug-ge.ch/sites/interhug/files/str...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Articles AFIB RSNA 2017 V1 - HUG</td>\n",
       "      <td>Le rôle de l'imagerie est central tant au nive...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://ug.linkedin.com/pub/michelle-alonda/5a...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Michelle ALONDA - Technical Marketing Engineer...</td>\n",
       "      <td>Je suis Alonda Michelle</td>\n",
       "      <td>13</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.bigdataparis.com/2019/webinars/</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Les mercredis du Big Data | Webinars du congrè...</td>\n",
       "      <td>Participez aux webinars Big Data Paris</td>\n",
       "      <td>14</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://www.presseagence.fr/lettre-economique-p...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>NICE : 18ème Festival d&amp;rsquo;Opérette et comé...</td>\n",
       "      <td>\"</td>\n",
       "      <td>15</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.theses.fr/2020BORD0227.pdf</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>docteur de l'université de bordeaux - Thèses</td>\n",
       "      <td>L'avancée de l'étude de la cognition collective</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>http://www.ausimaroc.com/wp-content/uploads/20...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Éditorial - AUSIM MAROC</td>\n",
       "      <td>Oct 26</td>\n",
       "      <td>17</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.zumtobel.com/PDB/Ressource/teaser/...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Un design centré sur l'utilisateur - Zumtobel</td>\n",
       "      <td>signifie pour l'aménagement des espaces de ven...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.slideshare.net/pascaloup/rapport-a...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Rapport annuel TIBCO - Exercice 2015 - SlideShare</td>\n",
       "      <td>Dec 20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.studyinfrance.sg/wp-content/upload...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>skema business school - Choose France! Educati...</td>\n",
       "      <td>values and DNA of our research</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  ... score\n",
       "0   https://www2.deloitte.com/content/dam/Deloitte...  ...  0.95\n",
       "1   https://www.oezratty.net/wordpress/wp-content/...  ...  0.90\n",
       "2     https://www.ebg.net/publications/pdf/100063.pdf  ...  0.85\n",
       "3   https://www.people-doc.fr/transformation-digit...  ...  0.80\n",
       "4   https://espas.secure.europarl.europa.eu/orbis/...  ...  0.75\n",
       "5   https://www.aijobs.tech/fr/j/t/emplois-chef-de...  ...  0.70\n",
       "6   https://fr.indeed.com/Emplois-Business-Intelli...  ...  0.65\n",
       "7   https://www.tableau.com/fr-fr/partners/search?...  ...  0.60\n",
       "8   https://www.tableau.com/fr-fr/partners/allianc...  ...  0.55\n",
       "9   http://lacgt44.fr/IMG/pdf/20180214_numerique_l...  ...  0.50\n",
       "10  https://www.sofimac-im.com/communiques-de-pres...  ...  0.45\n",
       "11  https://www.hug-ge.ch/sites/interhug/files/str...  ...  0.40\n",
       "12  https://ug.linkedin.com/pub/michelle-alonda/5a...  ...  0.35\n",
       "13        https://www.bigdataparis.com/2019/webinars/  ...  0.30\n",
       "14  http://www.presseagence.fr/lettre-economique-p...  ...  0.25\n",
       "15             https://www.theses.fr/2020BORD0227.pdf  ...  0.20\n",
       "16  http://www.ausimaroc.com/wp-content/uploads/20...  ...  0.15\n",
       "17  https://www.zumtobel.com/PDB/Ressource/teaser/...  ...  0.10\n",
       "18  https://www.slideshare.net/pascaloup/rapport-a...  ...  0.05\n",
       "19  https://www.studyinfrance.sg/wp-content/upload...  ...  0.00\n",
       "\n",
       "[20 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creation of lists that will contain the data we will extract\n",
    "links = []\n",
    "title = []\n",
    "query = []\n",
    "resume = []\n",
    "position = []\n",
    "\n",
    "#The general pattern to extract blocks of information\n",
    "pattern = re.compile(\"\\\"title\\\"[^}]+\")\n",
    "#The pattern that extracts url from the articles\n",
    "pattern_link = re.compile(\"\\\"link\\\"[^,]+\")\n",
    "#The pattern that extracts the article titles\n",
    "pattern_title = re.compile(\"\\\"title\\\"[^,]+\")\n",
    "#The pattern that extracts the summary of the articles\n",
    "pattern_resume = re.compile(\"\\\"snippet\\\"[^,]+\")\n",
    "#The pattern that extracts the position of the article in the Google search page\n",
    "pattern_pos = re.compile(\"\\\"position\\\"[^,]+\")\n",
    "\n",
    "#Creation of the output dataframe which will contain for each article its url, keywords, title, its position in the google page and its relevance score\n",
    "df_sources = pd.DataFrame(columns=['URL','Query','title','resume','position','score'])\n",
    "\n",
    "\n",
    "for source in list_source:\n",
    "    #Extraction of blocks from the variable source[0] which contains the source code crawled by the Google API crawler\n",
    "    bloc = pattern.findall(str(source[0]))\n",
    "    #Storing these blocks in a primary list\n",
    "    my_bloc = list([x for x in bloc])\n",
    "    #Processing blocks to obtain the required information\n",
    "    for i in my_bloc:\n",
    "      #Extracting the link from the block\n",
    "      link = pattern_link.findall(i)\n",
    "      #Extracting the title from the block\n",
    "      titre = pattern_title.findall(i)\n",
    "      #Extracting the summary from the block\n",
    "      snippet = pattern_resume.findall(i)\n",
    "      try :\n",
    "        #Remove all special characters that are not needed\n",
    "        links.append(link[0][8:-1])\n",
    "        title.append(titre[0][9:-1])\n",
    "        query.append(source[1])\n",
    "        resume.append(snippet[0][11:])\n",
    "      except :\n",
    "        a=1\n",
    "    #Extracting the position \n",
    "    pos = pattern_pos.findall(str(source[0]))\n",
    "    #Storage of the position in the first list\n",
    "    my_position = list([x for x in pos])\n",
    "    for i in my_position :\n",
    "      #Deletion of additional information\n",
    "      position.append(int(i[11:]))\n",
    "\n",
    "\n",
    "#Implementation of the dataframe\n",
    "df_sources['URL'] = links\n",
    "df_sources['Query'] = query\n",
    "df_sources['title'] = title\n",
    "df_sources['resume'] = resume\n",
    "df_sources['position'] = position\n",
    "for i in range(df_sources.shape[0]):\n",
    "  #Calculation of relevance score of each link from its rank (position) in the Google search page\n",
    "  df_sources['score'] = 1 - df_sources['position']/df_sources[df_sources['Query'] == df_sources['Query'].iloc[i]].shape[0]\n",
    "\n",
    "df_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E18nDep2ToG7"
   },
   "source": [
    "**Stockage de la dataframe de sortie dans un fichier json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "DELaelbHTzDK"
   },
   "outputs": [],
   "source": [
    "#Storing the dataframe in a Json file\n",
    "df_sources.to_json(\"df_sources.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "id": "EXm4wmZynq4X",
    "outputId": "4465faf0-c78a-4f6a-c0d7-a13e99f9eab3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ndef popCouple(couples = listCouple ,nbreCouples = 3) :\\nrandom.seed(41)\\nlistcouples =random.sample(couples,nbreCouples)\\nlisteAJeter = [i for i in couples if i not in listcouples ]\\nlist_source =[]\\npattern_results = re.compile(\"\"total_results\"[^,]+\")\\n\\n\\n\\ndf = (list(GoogleSpider().start_requests(listCouple=listcouples,length=p_length,requestNumber=nbreCouples)))\\ndf = df[0]  \\nlink = df[\\'URL\\']\\nquery = df[\\'Query\\']\\ncpt = 0\\nfor liens in link :\\n  print(liens)\\n  print(query[cpt])\\n  # URL scraping\\n  response = get(liens)\\n  print(response.text)\\n  # Test if the request was successful\\n  if response.status_code == 200:\\n      # Addition of the scraped google results and the corresponding query\\n      total_results = pattern_results.findall(response.text)\\n      total_results = list([x for x in total_results])\\n      print(total_results)\\n      list_source.append([response.text, query])\\n  cpt = cpt+1\\n  time.sleep(60)\\n\\n\\n  \\n\\n\\nreturn listcouples,listeAJeter\\na = popCouple()\\nprint(len(a[0]))\\nprint(len(a[1]))\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  #This section presents an alternative method of determining the popularity of each couple.\n",
    "  #the popularity calculation is based on the number of google results \n",
    "  \n",
    "  \"\"\"\n",
    "def popCouple(couples = listCouple ,nbreCouples = 3) :\n",
    "  random.seed(41)\n",
    "  listcouples =random.sample(couples,nbreCouples)\n",
    "  listeAJeter = [i for i in couples if i not in listcouples ]\n",
    "  list_source =[]\n",
    "  pattern_results = re.compile(\"\\\"total_results\\\"[^,]+\")\n",
    "  \n",
    "  \n",
    "  \n",
    "  df = (list(GoogleSpider().start_requests(listCouple=listcouples,length=p_length,requestNumber=nbreCouples)))\n",
    "  df = df[0]  \n",
    "  link = df['URL']\n",
    "  query = df['Query']\n",
    "  cpt = 0\n",
    "  for liens in link :\n",
    "    print(liens)\n",
    "    print(query[cpt])\n",
    "    # URL scraping\n",
    "    response = get(liens)\n",
    "    print(response.text)\n",
    "    # Test if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Addition of the scraped google results and the corresponding query\n",
    "        total_results = pattern_results.findall(response.text)\n",
    "        total_results = list([x for x in total_results])\n",
    "        print(total_results)\n",
    "        list_source.append([response.text, query])\n",
    "    cpt = cpt+1\n",
    "    time.sleep(60)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "  return listcouples,listeAJeter\n",
    "a = popCouple()\n",
    "print(len(a[0]))\n",
    "print(len(a[1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7Q8py9vl0jr"
   },
   "source": [
    "#Transition entre la deuxième et la troisième étape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "TKgSsmbYMjEJ",
    "outputId": "13b2f394-7abe-4cf9-8567-2d70f6071df3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Query</th>\n",
       "      <th>title</th>\n",
       "      <th>resume</th>\n",
       "      <th>position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www2.deloitte.com/content/dam/Deloitte...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>La révolution de l'intelligence - Préparer l'a...</td>\n",
       "      <td>apporté son lot de richesse et d'innovation; e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.oezratty.net/wordpress/wp-content/...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Les usages de l'intelligence artificielle - Ol...</td>\n",
       "      <td>Nov 18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ebg.net/publications/pdf/100063.pdf</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Banques / Assurances - l'EBG</td>\n",
       "      <td>2// Banques / Assurances : Comment la data lea...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.people-doc.fr/transformation-digit...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Définitions RH - Transformation digitale et Fu...</td>\n",
       "      <td>Toutes les définitions RH du Future of Work su...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://espas.secure.europarl.europa.eu/orbis/...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Données médicales - European Strategy and Poli...</td>\n",
       "      <td>B. Poursuivre la consolidation de l'infrastruc...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.aijobs.tech/fr/j/t/emplois-chef-de...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Emplois : Chef De Projet - janvier 2021 - AI J...</td>\n",
       "      <td>A la recherche d'un emploi : Chef De Projet ? ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://fr.indeed.com/Emplois-Business-Intelli...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Emplois : Business Intelligence Manager - janv...</td>\n",
       "      <td>Vous êtes à la recherche d'un emploi : Busines...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.tableau.com/fr-fr/partners/search?...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Trouver un partenaire - Tableau Software</td>\n",
       "      <td>DATA SEMANTICS has the ability to work with Mu...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.tableau.com/fr-fr/partners/allianc...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Trouver un partenaire | Tableau Software</td>\n",
       "      <td>DECIDEOM est expert dans le domaine de l'infor...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://lacgt44.fr/IMG/pdf/20180214_numerique_l...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>20180214_numerique_livret_v2_sr_rc_ca_v3_1_.pd...</td>\n",
       "      <td>18. V. DE L'UTILITÉ DU SYNDICALISME CGT DANS L...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.sofimac-im.com/communiques-de-pres...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Communiqués de presse - Sofimac Investment Man...</td>\n",
       "      <td>Bruno Le Maire</td>\n",
       "      <td>11</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.hug-ge.ch/sites/interhug/files/str...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Articles AFIB RSNA 2017 V1 - HUG</td>\n",
       "      <td>Le rôle de l'imagerie est central tant au nive...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://ug.linkedin.com/pub/michelle-alonda/5a...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Michelle ALONDA - Technical Marketing Engineer...</td>\n",
       "      <td>Je suis Alonda Michelle</td>\n",
       "      <td>13</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.bigdataparis.com/2019/webinars/</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Les mercredis du Big Data | Webinars du congrè...</td>\n",
       "      <td>Participez aux webinars Big Data Paris</td>\n",
       "      <td>14</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://www.presseagence.fr/lettre-economique-p...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>NICE : 18ème Festival d&amp;rsquo;Opérette et comé...</td>\n",
       "      <td>\"</td>\n",
       "      <td>15</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.theses.fr/2020BORD0227.pdf</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>docteur de l'université de bordeaux - Thèses</td>\n",
       "      <td>L'avancée de l'étude de la cognition collective</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>http://www.ausimaroc.com/wp-content/uploads/20...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Éditorial - AUSIM MAROC</td>\n",
       "      <td>Oct 26</td>\n",
       "      <td>17</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.zumtobel.com/PDB/Ressource/teaser/...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Un design centré sur l'utilisateur - Zumtobel</td>\n",
       "      <td>signifie pour l'aménagement des espaces de ven...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.slideshare.net/pascaloup/rapport-a...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>Rapport annuel TIBCO - Exercice 2015 - SlideShare</td>\n",
       "      <td>Dec 20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.studyinfrance.sg/wp-content/upload...</td>\n",
       "      <td>(\"pilotage de l'achat\" AND \"augmented intellig...</td>\n",
       "      <td>skema business school - Choose France! Educati...</td>\n",
       "      <td>values and DNA of our research</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  ... score\n",
       "0   https://www2.deloitte.com/content/dam/Deloitte...  ...  0.95\n",
       "1   https://www.oezratty.net/wordpress/wp-content/...  ...  0.90\n",
       "2     https://www.ebg.net/publications/pdf/100063.pdf  ...  0.85\n",
       "3   https://www.people-doc.fr/transformation-digit...  ...  0.80\n",
       "4   https://espas.secure.europarl.europa.eu/orbis/...  ...  0.75\n",
       "5   https://www.aijobs.tech/fr/j/t/emplois-chef-de...  ...  0.70\n",
       "6   https://fr.indeed.com/Emplois-Business-Intelli...  ...  0.65\n",
       "7   https://www.tableau.com/fr-fr/partners/search?...  ...  0.60\n",
       "8   https://www.tableau.com/fr-fr/partners/allianc...  ...  0.55\n",
       "9   http://lacgt44.fr/IMG/pdf/20180214_numerique_l...  ...  0.50\n",
       "10  https://www.sofimac-im.com/communiques-de-pres...  ...  0.45\n",
       "11  https://www.hug-ge.ch/sites/interhug/files/str...  ...  0.40\n",
       "12  https://ug.linkedin.com/pub/michelle-alonda/5a...  ...  0.35\n",
       "13        https://www.bigdataparis.com/2019/webinars/  ...  0.30\n",
       "14  http://www.presseagence.fr/lettre-economique-p...  ...  0.25\n",
       "15             https://www.theses.fr/2020BORD0227.pdf  ...  0.20\n",
       "16  http://www.ausimaroc.com/wp-content/uploads/20...  ...  0.15\n",
       "17  https://www.zumtobel.com/PDB/Ressource/teaser/...  ...  0.10\n",
       "18  https://www.slideshare.net/pascaloup/rapport-a...  ...  0.05\n",
       "19  https://www.studyinfrance.sg/wp-content/upload...  ...  0.00\n",
       "\n",
       "[20 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cas ou on récupère les données de la deuxième étape\n",
    "df_work = df_sources\n",
    "df_work\n",
    "#-----------------------------------------------#\n",
    "#Cas ou on importe des données json sans la colonnes words\n",
    "\n",
    "#df_work = pd.read_json('df_crawling_clean.json',orient='split')\n",
    "#df_work = df.rename(columns={\"Title\": \"title\", \"Snippet\": 'resume'})\n",
    "#df_work = df_work.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "tZXxL7yBLmUa"
   },
   "outputs": [],
   "source": [
    "#words cleaning\n",
    "def cleandesc(desc):\n",
    "    \"\"\" \n",
    "    word cleaning \n",
    "\n",
    "    Parameter :\n",
    "        descn : word we want to clean up  \n",
    "    \n",
    "    Out :\n",
    "        proxy_url : cleaned word\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    " \n",
    "    sent = desc\n",
    "    #Lower case\n",
    "    sent = \"\".join([x.lower() if x.isalpha()  else \" \" for x in sent])\n",
    "    Porter=SnowballStemmer('french')\n",
    "    #Clean stop words\n",
    "    sent = \" \".join([Porter.stem(x) if x.lower() not in stop_words  else \"\" for x in sent.split()])\n",
    "    sent = \" \".join(sent.split())\n",
    "    \n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RuPwd95I463"
   },
   "source": [
    "- Environ 60 itérations par seconde pour le calcule \n",
    "- La fonction prend environ 28 minutes pour un dataFrame de 28 000 lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "GtdCr_N5Gd83"
   },
   "outputs": [],
   "source": [
    "def lexique_finder_row(row,lexique_gestion,lexique_innovation): \n",
    "    \"\"\"Documentation\n",
    "    This function is taken from @Corentin PM code\n",
    "    \"\"\"\n",
    "    #gérer les dérivés (pluriel, féminin, mot composé, etc)\n",
    "    dico={}  #{mot1:[gestion ou innovation, nb d'apparition dans le titre, nb d'apparition dans les resume]}\n",
    "    for mot_gestion in (lexique_gestion) :\n",
    "      #We search management words on resume and title \n",
    "\n",
    "      mot=cleandesc(mot_gestion)\n",
    "      nresume=row['resume'].count(mot+' ')\n",
    "      ntitre=row['title'].count(mot+' ')\n",
    "      dico[mot_gestion]=[0,ntitre,nresume]\n",
    "    for mot_innovation in lexique_innovation :\n",
    "      #We search innovation words on resume and title \n",
    "      mot=cleandesc(mot_innovation)\n",
    "      nresume=row['resume'].count(mot+' ')\n",
    "      ntitre=row['title'].count(mot+' ')\n",
    "      dico[mot_innovation]=[0,ntitre,nresume]\n",
    "    final_df=pd.DataFrame.from_dict(dico, orient='index', columns=['Gestion/Innovation', 'nb_in_title', 'nb_in_resume'])\n",
    "    return final_df\n",
    "\n",
    "def lexique_finder_google(df,lexique_gestion,lexique_innovation): \n",
    "    \"\"\"Documentation\n",
    "    This function is taken from @Corentin PM code\n",
    "    \"\"\"\n",
    "    #list coll\n",
    "    list_df=[]\n",
    "    for index, row in (df.iterrows()):\n",
    "      \n",
    "      list_df.append(lexique_finder_row(row,lexique_gestion,lexique_innovation))\n",
    "    return list_df\n",
    "\n",
    "df_work['title']= [cleandesc(x.title) for x in (df_work.itertuples())]\n",
    "df_work['resume']= [cleandesc(x.resume) for x in df_work.itertuples()]\n",
    "\n",
    "listeDf = lexique_finder_google(df_work,gestion,innovation) \n",
    "\n",
    "listeMots = []\n",
    "for i in listeDf :\n",
    "  listeMots.append(list(i[(i['nb_in_title']>0) | (i['nb_in_resume']>0 )].index))\n",
    "\n",
    "\n",
    "df_work['mots'] = listeMots\n",
    "#listeMots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsqX6mz7rZbf",
    "outputId": "67c92100-94e1-46b4-a9c9-d04793f971c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M14',\n",
       "  'M832',\n",
       "  'M22',\n",
       "  'pilotage',\n",
       "  'innovation',\n",
       "  '3d',\n",
       "  'ar',\n",
       "  'augmented intelligence',\n",
       "  '5g',\n",
       "  '4.0'],\n",
       " ['M14', 'M832', 'M22', 'intelligence artificielle', '3d', '5g', '4.0'],\n",
       " ['M14',\n",
       "  'M4X',\n",
       "  'M832',\n",
       "  'M22',\n",
       "  'pilotage',\n",
       "  'activités',\n",
       "  '3d',\n",
       "  'augmented intelligence',\n",
       "  '5g',\n",
       "  '4.0'],\n",
       " ['M14', 'M832', 'M22', 'RH', '3d', '5g', '4.0', 'du futur'],\n",
       " ['Administration',\n",
       "  'M14',\n",
       "  'M832',\n",
       "  'M22',\n",
       "  'pilotage',\n",
       "  '3d',\n",
       "  'vr',\n",
       "  'augmented intelligence',\n",
       "  '5g',\n",
       "  '4.0'],\n",
       " ['M14', 'M832', 'M22', 'emplois', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', 'emplois', '3d', '5g', '4.0'],\n",
       " ['M14', 'M4X', 'M832', 'M22', '3d', '5g', '4.0'],\n",
       " ['M14', 'M832', 'M22', 'formation', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', 'iot', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '5g', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', 'ar', 'big data', 'big-data', '5g', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', 'université 4.0', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '4.0'],\n",
       " ['M14',\n",
       "  'M832',\n",
       "  'M22',\n",
       "  'pilotage',\n",
       "  '3d',\n",
       "  'augmented intelligence',\n",
       "  '5g',\n",
       "  '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '4.0'],\n",
       " ['M14', 'M832', 'M22', '3d', '4.0']]"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listeMots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w5rV1leWBtB"
   },
   "source": [
    "#Transition entre la Troisème et la quatrième étape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "nUbV-BKrmjTj"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------#\n",
    "#Cas ou on importe des données depuis un csv ou un json , le df doit contenir une colonne mots avec les listes des mots contenus dans les titres et articles\n",
    "\n",
    "#df_work = pd.read_csv('df7000.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTBWbWb4UgbX"
   },
   "source": [
    "**Implémentation de la fonction qui fait le produit cartésien entre les mots du lexique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "prfuj1nUZEmg"
   },
   "outputs": [],
   "source": [
    "def produitCartesien(liste1: list,liste2: list) -> list() :\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "      liste1: list of strings containing words for queries\n",
    "      liste2: same.\n",
    "\n",
    "    Out:\n",
    "      listeRetour: list containing cartesian product of arguments\n",
    "    \"\"\"\n",
    "    listeRetour: list = []\n",
    "    for i in liste1 :\n",
    "      for j in liste2:\n",
    "        listeRetour.append([i,j])\n",
    "    return listeRetour\n",
    "\n",
    "listCouples = produitCartesien(list(set(gestion)),innovation)\n",
    "#change list of 2words into a string separated with a space\n",
    "vraiListeCouples = [' '.join(i) for i in listCouples] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vE0XXXfnUlPn"
   },
   "source": [
    "**Implémentation de la fonction qui calcule :**\n",
    "- L'occurence de chaque couple de mot clé dans le titre et le resumé\n",
    "- L'évolution de ces couples \n",
    "- Le score de pertinence de ces couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "zaf9zoil5JXa"
   },
   "outputs": [],
   "source": [
    "def popularite_motscles(data: pd.DataFrame,dataAnterieur=False,\n",
    "                        lexique_gestion: list = gestion,\n",
    "                        lexique_innovation: list = innovation,\n",
    "                        listCouple: list = vraiListeCouples) -> pd.DataFrame() :\n",
    "    \"\"\" Documentation\n",
    "      Calculation of popularity for each keyword \n",
    "\n",
    "      Parameter :\n",
    "          data : dataframe containing the keywords to analyze \n",
    "          dataAnterieur = old dataframe containing the data to be compared \n",
    "          lexique_gestion = management lexicon \n",
    "          lexique_innovation = innovation lexixon \n",
    "          listCouple = list of keyword pairs \n",
    "      \n",
    "      Out :\n",
    "          dfPopularite : dataframe containing the list of keywords, \n",
    "          their occurrence and their evolution\n",
    "    \"\"\"\n",
    "\n",
    "    dfPopularite = pd.DataFrame(\n",
    "        columns =['couples','occurence','evolution','score']\n",
    "        )\n",
    "    dfPopularite['couples'] = vraiListeCouples\n",
    "    dfPopularite.index = dfPopularite['couples']\n",
    "    motsgestions: list = []\n",
    "    motsinnovations: list = []\n",
    "    couples: list = []\n",
    "    # separation of the words management and innovation \n",
    "    for i in range((data.shape[0])):\n",
    "      #This condition treats the case when a list is loaded from the dataframe\n",
    "      if type(data['mots'].iloc[i]) == list : \n",
    "        motsgestions.append(\n",
    "            [j for j in data['mots'].iloc[i] if j in lexique_gestion]\n",
    "            )\n",
    "        motsinnovations.append(\n",
    "            [j for j in data['mots'].iloc[i] if j in lexique_innovation]\n",
    "            )\n",
    "      else :\n",
    "        data['mots'].iloc[i] = ast.literal_eval(data['mots'].iloc[i])\n",
    "        \n",
    "        motsgestions.append(\n",
    "            [j for j in data['mots'].iloc[i] if j in lexique_gestion]\n",
    "            )\n",
    "        motsinnovations.append(\n",
    "            [j for j in data['mots'].iloc[i] if j in lexique_innovation]\n",
    "            )\n",
    "  \n",
    "        \n",
    "    #creation of colums\n",
    "    data['mots innovation'] = motsinnovations\n",
    "    data['mots gestion'] = motsgestions\n",
    "    \n",
    "    #generation of couples \n",
    "    for i in range(data.shape[0]) :\n",
    "      couples.append(\n",
    "          produitCartesien(data['mots gestion'].iloc[i],\n",
    "                           data['mots innovation'].iloc[i])\n",
    "          )\n",
    "    data['couples'] = couples\n",
    "    dictOccurences: dict = {}\n",
    "    for ligne in range(data.shape[0]) :\n",
    "      for couple in data['couples'].iloc[ligne] :\n",
    "        if ' '.join(couple) in dictOccurences.keys() :\n",
    "          dictOccurences[' '.join(couple)] +=  1\n",
    "        else :\n",
    "          dictOccurences[' '.join(couple)] =  1\n",
    "    \n",
    "    for i in dictOccurences.keys() :\n",
    "      \n",
    "      dfPopularite['occurence'].loc[i] = dictOccurences[i]\n",
    "    dfPopularite['occurence'] = dfPopularite['occurence'].fillna(0)\n",
    "    #Calculation of evolution\n",
    "    if type(dataAnterieur) != bool:\n",
    "      for i in (dfPopularite.index) :\n",
    "        try :\n",
    "          if dataAnterieur['occurence'].loc[i]  != 0:\n",
    "            dfPopularite['evolution'].loc[i] = (\n",
    "                dfPopularite['occurence'].loc[i] / dataAnterieur['occurence'].loc[i]-1)*100\n",
    "          \n",
    "          elif dataAnterieur['occurence'].loc[i]  == 0 and dfPopularite['occurence'].loc[i]  != 0 :\n",
    "            dfPopularite['evolution'].loc[i] = 100\n",
    "          elif dataAnterieur['occurence'].loc[i]  == 0 and dfPopularite['occurence'].loc[i]  == 0  :\n",
    "            dfPopularite['evolution'].loc[i] = 0\n",
    "        except :\n",
    "          print( dataAnterieur['occurence'].loc[i])\n",
    "\n",
    "    dfPopularite['score'] = ((dfPopularite['occurence']/dfPopularite['occurence'].max())*100 + dfPopularite['evolution'])/2\n",
    "\n",
    "    return dfPopularite.sort_values('occurence',ascending=False)\n",
    "anciendf = popularite_motscles(df_work)  #Cas avec pas d'historique \n",
    "#nouveaudf = popularite_motscles(dfTest2,anciendf) #cas ou l'on possède un historique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "G8j9QXppVXtZ",
    "outputId": "8dd7c56d-ca0e-4952-db65-0ae39ceac1a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>couples</th>\n",
       "      <th>occurence</th>\n",
       "      <th>evolution</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>couples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M22 4.0</th>\n",
       "      <td>M22 4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 3d</th>\n",
       "      <td>M14 3d</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M832 4.0</th>\n",
       "      <td>M832 4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M22 3d</th>\n",
       "      <td>M22 3d</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M832 3d</th>\n",
       "      <td>M832 3d</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 4.0</th>\n",
       "      <td>M14 4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M832 5g</th>\n",
       "      <td>M832 5g</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M22 5g</th>\n",
       "      <td>M22 5g</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 5g</th>\n",
       "      <td>M14 5g</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilotage 5g</th>\n",
       "      <td>pilotage 5g</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilotage 4.0</th>\n",
       "      <td>pilotage 4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M22 augmented intelligence</th>\n",
       "      <td>M22 augmented intelligence</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilotage 3d</th>\n",
       "      <td>pilotage 3d</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilotage augmented intelligence</th>\n",
       "      <td>pilotage augmented intelligence</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M832 augmented intelligence</th>\n",
       "      <td>M832 augmented intelligence</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 augmented intelligence</th>\n",
       "      <td>M14 augmented intelligence</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 ar</th>\n",
       "      <td>M14 ar</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M832 ar</th>\n",
       "      <td>M832 ar</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M4X 3d</th>\n",
       "      <td>M4X 3d</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M22 ar</th>\n",
       "      <td>M22 ar</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M4X 5g</th>\n",
       "      <td>M4X 5g</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M4X 4.0</th>\n",
       "      <td>M4X 4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emplois 4.0</th>\n",
       "      <td>emplois 4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emplois 3d</th>\n",
       "      <td>emplois 3d</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 iot</th>\n",
       "      <td>M14 iot</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 intelligence artificielle</th>\n",
       "      <td>M14 intelligence artificielle</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M22 iot</th>\n",
       "      <td>M22 iot</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 vr</th>\n",
       "      <td>M14 vr</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilotage innovation</th>\n",
       "      <td>pilotage innovation</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 du futur</th>\n",
       "      <td>M14 du futur</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formation 3d</th>\n",
       "      <td>formation 3d</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 big-data</th>\n",
       "      <td>M14 big-data</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 big data</th>\n",
       "      <td>M14 big data</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M832 du futur</th>\n",
       "      <td>M832 du futur</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M22 intelligence artificielle</th>\n",
       "      <td>M22 intelligence artificielle</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administration 4.0</th>\n",
       "      <td>Administration 4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH 5g</th>\n",
       "      <td>RH 5g</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M14 innovation</th>\n",
       "      <td>M14 innovation</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activités 4.0</th>\n",
       "      <td>activités 4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilotage vr</th>\n",
       "      <td>pilotage vr</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         couples  ...  score\n",
       "couples                                                           ...       \n",
       "M22 4.0                                                  M22 4.0  ...    NaN\n",
       "M14 3d                                                    M14 3d  ...    NaN\n",
       "M832 4.0                                                M832 4.0  ...    NaN\n",
       "M22 3d                                                    M22 3d  ...    NaN\n",
       "M832 3d                                                  M832 3d  ...    NaN\n",
       "M14 4.0                                                  M14 4.0  ...    NaN\n",
       "M832 5g                                                  M832 5g  ...    NaN\n",
       "M22 5g                                                    M22 5g  ...    NaN\n",
       "M14 5g                                                    M14 5g  ...    NaN\n",
       "pilotage 5g                                          pilotage 5g  ...    NaN\n",
       "pilotage 4.0                                        pilotage 4.0  ...    NaN\n",
       "M22 augmented intelligence            M22 augmented intelligence  ...    NaN\n",
       "pilotage 3d                                          pilotage 3d  ...    NaN\n",
       "pilotage augmented intelligence  pilotage augmented intelligence  ...    NaN\n",
       "M832 augmented intelligence          M832 augmented intelligence  ...    NaN\n",
       "M14 augmented intelligence            M14 augmented intelligence  ...    NaN\n",
       "M14 ar                                                    M14 ar  ...    NaN\n",
       "M832 ar                                                  M832 ar  ...    NaN\n",
       "M4X 3d                                                    M4X 3d  ...    NaN\n",
       "M22 ar                                                    M22 ar  ...    NaN\n",
       "M4X 5g                                                    M4X 5g  ...    NaN\n",
       "M4X 4.0                                                  M4X 4.0  ...    NaN\n",
       "emplois 4.0                                          emplois 4.0  ...    NaN\n",
       "emplois 3d                                            emplois 3d  ...    NaN\n",
       "M14 iot                                                  M14 iot  ...    NaN\n",
       "M14 intelligence artificielle      M14 intelligence artificielle  ...    NaN\n",
       "M22 iot                                                  M22 iot  ...    NaN\n",
       "M14 vr                                                    M14 vr  ...    NaN\n",
       "pilotage innovation                          pilotage innovation  ...    NaN\n",
       "M14 du futur                                        M14 du futur  ...    NaN\n",
       "formation 3d                                        formation 3d  ...    NaN\n",
       "M14 big-data                                        M14 big-data  ...    NaN\n",
       "M14 big data                                        M14 big data  ...    NaN\n",
       "M832 du futur                                      M832 du futur  ...    NaN\n",
       "M22 intelligence artificielle      M22 intelligence artificielle  ...    NaN\n",
       "Administration 4.0                            Administration 4.0  ...    NaN\n",
       "RH 5g                                                      RH 5g  ...    NaN\n",
       "M14 innovation                                    M14 innovation  ...    NaN\n",
       "activités 4.0                                      activités 4.0  ...    NaN\n",
       "pilotage vr                                          pilotage vr  ...    NaN\n",
       "\n",
       "[40 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anciendf.head(40).sort_values('occurence',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeGjBsqFg7YI"
   },
   "source": [
    "Implémentation d'un algo de machine learning pour catégoriser les différents couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "collapsed": true,
    "id": "X0THLvHkI-EL",
    "outputId": "cb156ab7-a2be-4a63-e474-58f631162878"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-38abbee927a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'occurence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'evolution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['occurence', 'evolution'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "X = df[['occurence','evolution']]\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=3).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Wrj7zb6l-wW"
   },
   "source": [
    "Cette méthode permet de retrouver le nombre d'article répondant à un couple de mots clefs donnés. Nous obtenons donc à la fin deux variables représentant, pour la première, l'occurence du couple de mot et, pour la deuxième, son évolution depuis la dernière étude. Un score global est fait en prenant ces deux variables, l'occurance et l'évolution, permettant de mettre en avant des mots clefs ayant une occurence forte et ceux ayant une occurence faible mais une forte évolution ascendante qui permettent de comprendre qu'ils sont importants à surveiller ce qui permettrait d'être les premiers sur l'information. La méthode de score que nous avons utilisé est naïve (ici une moyenne) et mérite d'être amélioré. \n",
    "\n",
    "Plusieurs méthodes de sélections sont possibles :  \n",
    "  - faire une selection du top N selon le score global\n",
    "  - faire une selection selon un seuil de score\n",
    "  - faire une selection avec des méthodes de classification\n",
    "  \n",
    "Cette dernière solution n'a pas pu être mise en place faute de temps, nous avions dans l'idée de choisir une méthode de classification (non supervisé, ou semi-supervisé) pour choisir une ou plusieurs classes. \n",
    "La première méthode naïve pensée était d'utiliser la méthode des kmeans pour trouver ces individus. Mais d'autre méthodes, comme des arbres de classification, SVM ou méthode à noyaux par exemple. \n",
    "Un processus de caractérisation des classes auraient aussi dû être mis en place. Une première façon de le concevoir est de selectionner par exemple les deux classes (si le nombre de classe est supérieur à 3) ayant respectivement l'ocurrence moyenne la plus forte et l'évolution moyenne la plus forte. \n",
    "\n",
    "## Conclusion \n",
    "\n",
    "Cette problématique est finalement essentielle dans le processus d'identification des nouvelles sources afin de réduire le nombre de requête au quotidien durant la période d'étude des tendances. En divisant la liste des couples de mots clefs par 2 nous pouvons facilement réduire le nombre de requête par mois. Pour répondre aux contraintes de l'utilisation d'un moteur de recherche (attendre 1 minute entre chaque requête), cette liste aura vocation a être réduite plus drastiquement. \n",
    "\n",
    "La solution qui a été mis en place n'est qu'une ébauche de ce qui serait possible et mérite d'être améliorée afin d'optimiser la solution globale qui est d'identifier de nouvelles sources pertinentes et d'exploiter ces sources en récoltant les articles qui en parlent. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "g2_crawling_POC_Popularite_Couples.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
