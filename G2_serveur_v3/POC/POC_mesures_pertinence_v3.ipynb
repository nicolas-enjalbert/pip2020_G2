{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Tuesday 12th January 2021 \n",
    "\n",
    "# **POC mesures de pertinence**\n",
    "**Group 2 - Recherche de nouvelles sources**  \n",
    "*Projet Inter-Promo 2021 de la formation SID, Université Paul Sabatier, Toulouse*\n",
    "\n",
    "@authors : Corentin Prat-Marca, Nicolas Enjalbert Courrech, Sonia Bezombe, Flavien Caminade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un point clef de la veille technologique automatisée est de définir des nouvelles sources répondant au thème de cette veille. \n",
    "Dans le cadre de ce projet, l'identification des nouvelles sources pertinentes c'est fait en plusieurs étapes. La première est de récupérer un nombre important d'article. Pour cela, une solution utilisant un moteur de recherche et un ensemble d'équation. Ces points sont détaillés dans le POC ou rapport dédié. Le résultat de cette étape-ci est un ensemble d'article répondant plus ou moins aux requêtes.  \n",
    "L'étape suivant permet de mesurer la pertinence d'un article et par agrégation d'un site entier. Le but de cette étape est de définir si un site est qualifié de pertinent et le positionner dans la liste des sites à surveiller (ici en les scrappant) tous les jours.\n",
    "Ce document décrit des mesures qui ont été pensées durant le projet. \n",
    "\n",
    "Ces mesures sont calculées à partir d'un date frame obtenu après les résultats de moteur de recherche contenant :  \n",
    "  * art_url : l'url de l'article\n",
    "  * src_name : le nom du site\n",
    "  * src_url : l'url du site (page d'accueil)\n",
    "  * query : mots clefs utilisés pour effectuer la recherche\n",
    "  * title : titre proposé par le moteur de recherche\n",
    "  * snippet : résumé proposé par le moteur de recherche\n",
    "  * rank : position de l'article dans le résultat du moteur de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure de popularité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première mesure mise en place est très naïve : elle mesure la popularité d'un site, c'est-à-dire, le nombre de fois que le site est appartu à partir d'un ensemble de requête. \n",
    "Un simple *count* répond à cette question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSite(df):\n",
    "    return df.groupby('src_name').count().reset_index()\n",
    "\n",
    "def popularite(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Contains : art_url, src_name, src_url.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Contains : src_name, popularity score.\n",
    "\n",
    "    \"\"\"\n",
    "    df1 = countSite(df)\n",
    "    df1[\"popularity\"] = [x/np.max(df1.art_url) for x in df1.art_url]\n",
    "    df_final = df1[['src_name','popularity']]\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette mesure ne répond pas complétement à la question de pertinence. Les moteurs de recherche retournent souvent en priorité une liste de sites populaires, car très utiliser par les utilisateurs des moteurs de recherche, comme des réseaux sociaux, dictionnaires, traducteurs ou encyclopédies. Ces sites nous ont été retournés lors de notre première mise en place de récupération des résultats de moteurs de recherche. \n",
    "\n",
    "Cet ensemble de sites ne répondent pas à notre recherche d'articles innovants et très actuels. De plus, il ne prend pas en compte de site moins populaire mais contenant des articles très pertinents. Cette solution naïve n'est donc pas judicieuse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Mesure du rang\n",
    "\n",
    "Cette mesure s'obtient en se basant sur l'ordonancement des articles par le moteur de recherche. Intuitivement, un article étant classé en première position répond mieux à la requête de recherche qu'un article étant placé en dernière position. \n",
    "\n",
    "La fonction _score_rank_ permet de mettre en valeur le rang de position en attriuant un score élevé à l'article étant au premier rang et en aggrégeant par la moyenne ces scores par sites. \n",
    "\n",
    "$scoreArticle_i = 1 - \\frac{rang_i}{card(R)} $  avec R l'ensemble des résultats de la requête donnant l'article i. \n",
    "\n",
    "La fonction d'aggrégation est la moyenne de ces scores groupés par sites $\\frac{1}{card(c)} \\sum_{c \\in C} scoreArticle_c $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_rank(df) :\n",
    "    for i in range(df.shape[0]):\n",
    "        df['score_rank'] = 1 - df['position']/df[df['query'] == df['query'].iloc[i]].shape[0]\n",
    "        df_result_rank = df.groupby('src_name')['score_rank'].mean()\n",
    "    return (df_result_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce score est aussi biaisé par les sites populaires qui sont placé souvent en première position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure du contenu de la requête dans le titre et le résumé\n",
    "\n",
    "Cette mesure vise à savoir si les mots de la requête se retrouve en leur totalité ou non dans le titre et le résumé proposé par le moteur de recherche. \n",
    "Cette mesure propose un score compris entre 0 et 1 pour chaque site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_query_words(df) :\n",
    "    \"\"\"\n",
    "    Categorize an article if it contains his 'innovation' or 'gestion' query word\n",
    "    \"\"\"\n",
    "    df = transform_data(df)\n",
    "    df['cat_pertinence'] = ''\n",
    "    df['common_words'] = ''\n",
    "    df['relevance_query']=0.00\n",
    "    relevance_query : list = [] #list that will store the relevance score,\n",
    "    #pertinence_j = [] #list that will store the number of the line concerned\n",
    "    df_relevance = pd.DataFrame(columns=['nb_row','score']).set_index('nb_row') #creation of a df allowing to have the score for each line,\n",
    "    for j in range (len(df)): # for each line of the df,\n",
    "    innov : int = 0 #initialization of a variable to count the number of words in the innovation lexicon \n",
    "    gest : int = 0 #...the same for the management lexicon\n",
    "    separator_or : list = list(df['query'][j].split(' or ')) #we store all pairs of the request in a separator_or list \n",
    "    relevance_listing : list = [] #list to store the relevance scores for each of the couples\n",
    "    list_find : list = [] #list to store words in common for each line,\n",
    "    for k in range (len(separator_or)): #for each of these couples,\n",
    "      nb_present : int = 0 #count the number of words in common\n",
    "      separator_and : list = list(separator_or[k].split(' and ')) #we store all the words of the couple of the query in a separator_and list \n",
    "      for i in range (len(separator_and)): #for all the words in the query,\n",
    "        if (df['title'][j].find(separator_and[i]) != -1) : #we look for it in the title, and if it's there... \n",
    "          if (i == 0): #if it's the first member of the couple, we've found a word of innovation \n",
    "            innov += 1\n",
    "          else : #If not, a word of management \n",
    "            gest += 1\n",
    "          nb_present = nb_present + 1 #increments the number of words in the query found.  \n",
    "          list_find.append(separator_and[i]+\";\")\n",
    "        if (df['resume'][j].find(separator_and[i]) != -1) : #then we look for it in the summary, and if it's there... \n",
    "          if (i == 0):\n",
    "            innov += 1\n",
    "          else :\n",
    "            gest += 1\n",
    "          nb_present += 1\n",
    "          list_find.append(separator_and[i]+\";\") #... we put it in a list\n",
    "          list_find = list(set(list_find))\n",
    "      relevance_query : float = (nb_present / len(separator_and))*100 #we calculate the relevance score nb of words found / nb of total words in the query\n",
    "      relevance_listing.append(relevance_query)\n",
    "      str = ' '.join(list_find) #...\n",
    "    df['common_words'][j]=str[:-1] #...we add the words found in the df\n",
    "    df_relevance = df_relevance.append({'nb_row': j}, ignore_index=True)\n",
    "    df_relevance['score'][j] = max(relevance_listing) #for each line, we take the best relevance of a couple,\n",
    "    df['relevance_query'][j] = df_relevance['score'][j]\n",
    "    nb = df_relevance['score'][j]\n",
    "    #and we categorize according to the score obtained :\n",
    "    if (nb>=100) : #all the words of at least one couple are found,\n",
    "      df['cat_pertinence'][j] = 'I&G'\n",
    "    else :\n",
    "      if (innov >= 1 and gest >= 1) : #words of innovation and gestion are found but not in the same couple,\n",
    "        df['cat_pertinence'][j] = 'I&G but not from the same couple'\n",
    "      elif (innov >= 1 and gest == 0) : #at least one word of innovation is found, but no gestion,\n",
    "        df['cat_pertinence'][j] = 'I'\n",
    "      elif (innov == 0 and gest >= 1): #at least one word of management is found but no innovation, \n",
    "        df['cat_pertinence'][j] = 'G'\n",
    "      else :\n",
    "        df['cat_pertinence'][j] = 'None' #no word is found \n",
    "    return(df)\n",
    "\n",
    "def result_score_def (df):\n",
    "    \"\"\"\n",
    "    Aggregate score by src_name\n",
    "    \"\"\"\n",
    "  df_relevance_query = common_query_words(df)\n",
    "  df_relevance_query['src_name'] = ''\n",
    "  for i in range (len(df_relevance_query)) :\n",
    "    df_relevance_query['src_name'][i] = site_name(df_relevance_query['art_url'][i])\n",
    "  df_result_score = df_relevance_query.groupby('src_name')['relevance_query'].mean()\n",
    "  return (df_result_score)\n",
    "\n",
    "def relevance_query (df) :\n",
    "    \"\"\"\n",
    "    normalize score to contains score between 0 and 1\n",
    "    \"\"\"\n",
    "  df_result_score = result_score_def(df)\n",
    "  df_result_score = df_result_score.reset_index()\n",
    "  df_result_score['relevance_query'] = df_result_score['relevance_query']/(max(df_result_score['relevance_query']))\n",
    "  return (df_result_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette mesure prend en compte les mots de la requête étant dans le titre et le résumé. Dans notre cas le moteur de recherche Google, choisi pour ce projet, utilise automatiquement aussi des synonymes des mots contenus dans la requête textuelle. Cette approche prends en compte des formes réduites des mots pouvant ainsi prendre en compte toutes les formes de notre recherche textuelle. \n",
    "\n",
    "Néanmoins, un synonyme ne répond pas à ces formes réduites puisque différents par leur racine. Cette mesure ne prend donc pas en compte un potentiel article très pertinent mais ne répondant qu'à des synonymes de la requête textuelle utilisée. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure : présence des mots du lexique dans l'article.\n",
    "\n",
    "Une première approche pour répondre à la problématique des synonymes est d'utiliser l'ensemble des mots clefs des lexiques proposés en entrée des requêtes textuelles. \n",
    "\n",
    "Les fonctions suivantes permettes de calculer ce score-ci.\n",
    "\n",
    "On cherche à attribuer un score à des articles scrappés en regardant combien on trouve de mots de chaque lexique. On choisit sur quels parties on se base (nom de l'article, résumé, contenu, etc), et on calcule un score dépendant du nombre de mots des lexiques (plus il y a de mots mieux c'est, si un article comporte 0 mots d'un lexique on pénalise) de la différence des nombres de mots de chaque lexique (on veut à peu près autant de mots de chaque lexique), et de la taille de l'article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubl2-Z5haKdH",
    "outputId": "b295acd6-69aa-4838-cbe0-1e6e89c48286"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/cmisid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk   #the importations for cleandesc\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer \n",
    "nltk.download('stopwords')\n",
    "stop_words=nltk.corpus.stopwords.words('french') #we're working on french articles\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def cleandesc(desc : str): #function to remove stopwords and suffixes\n",
    "    \"\"\"Documentation\n",
    "    Function took from @SoniaBezombes\n",
    "    \"\"\"\n",
    "    sent = desc\n",
    "    sent = \"\".join([x.lower() if x.isalpha()  else \" \" for x in sent])\n",
    "    Porter=SnowballStemmer('french')\n",
    "    sent = \" \".join([Porter.stem(x) if x.lower() not in stop_words  else \"\" for x in sent.split()])\n",
    "    sent = \" \".join(sent.split())\n",
    "    return sent\n",
    "\n",
    "def calcul_score(texte : str,lexique : list): \n",
    "    #function to count the number of words of a list in a text\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        texte : the text we're working on\n",
    "        lexique : the list of words we're looking for\n",
    "    Out :\n",
    "        somme : the number of lexique's words we found in texte\n",
    "    \"\"\"\n",
    "    somme : int = 0\n",
    "    for mot in lexique:\n",
    "        somme += texte.count(' '+mot+' ')\n",
    "    return somme\n",
    "\n",
    "\n",
    "#before using pertinence 4, we have to clean the columns we're gonna work on like that :\n",
    "#df_scrapped_articles['column_name']= [cleandesc(x.column_name) for x in df_scrapped_articles.itertuples()]\n",
    "#cleaning art_content all the time, just once\n",
    "#df_scrapped_articles['art_content']= [cleandesc(x.art_content) for x in df_work.itertuples()]\n",
    "\n",
    "def pertinence_4(df : pd.DataFrame , list_columns : list, \n",
    "                 lexiqueI : list, lexiqueG : list):\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        df : a data frame of scrapped articles. It must contains \n",
    "        a \"art_content\" columns to determine its size\n",
    "        \n",
    "        list_columns : the list of columns we want to count \n",
    "        the words of the two lexiques on. \n",
    "        \n",
    "        lexiqueI : the innovation lexique, it has to be a list\n",
    "        lexiqueG : the gestion lexique, it has to be a list\n",
    "    Out :\n",
    "        df : the same data but with the scores and the step to have it\n",
    "    \"\"\"\n",
    "    list_nom_colonne_I : list = [] #the list of the names of the innovation's score columns \n",
    "    list_nom_colonne_G : list = [] #the list of the names of the gestion's score columns \n",
    "    cleanedG : list = [cleandesc(mot) for mot in lexiqueG] #cleaning the gestion's lexique\n",
    "    cleanedI : list = [cleandesc(mot) for mot in lexiqueI] #cleaning the gestion's lexique\n",
    "\n",
    "    for columns in list_columns:\n",
    "\n",
    "        nomI : str ='score_innovation_'+columns #the name of the new columns : score_innovation_column_name or score_gestion_column_name\n",
    "        nomG : str ='score_gestion_'+columns\n",
    "        df[nomI]=[calcul_score(df.loc[i][columns], cleanedI) for i in range(len(df))] #creating the new columns using calcul_score, counting the number of words\n",
    "        df[nomG]=[calcul_score(df.loc[i][columns], cleanedG) for i in range(len(df))]\n",
    "        df['score_'+columns]=[df.loc[i][nomI]+df.loc[i][nomG] for i in range(len(df))] #new column, wich is the sum of gestion and innovation scores\n",
    "        list_nom_colonne_I.append(nomI)\n",
    "        list_nom_colonne_G.append(nomG)\n",
    "    \n",
    "    #length of the cleaned content of the article\n",
    "    df['taille_content'] = [len(df['art_content'][i]) for i in range(len(df))] \n",
    "    #sum of all the innovation's scores\n",
    "    df['score_I'] = df[list_nom_colonne_I].sum(axis = 1) \n",
    "    #sum of all the gestion's scores\n",
    "    df['score_G'] = df[list_nom_colonne_G].sum(axis = 1) \n",
    "    #absolute value of the difference of the number of gestion's words and innovation's words\n",
    "    df['score_abs'] = abs(df['score_I']-df['score_G'])\n",
    "    #finding if there is 0 gestion's words or 0 innovation's words, \n",
    "    #to penalise the articles which don't speak of innovation or gestion\n",
    "    df['detct_0'] = [0 if (x.score_I == 0) or (x.score_G == 0) else 1 for x in df.itertuples()] \n",
    "    \n",
    "    df['score_total'] = [(1.09*(x.score_I+x.score_G)-abs(x.score_I-x.score_G))*100/x.taille_content \n",
    "                         if x.detct_0 == 0 \n",
    "                         else (1.09*(x.score_I+x.score_G)-abs(x.score_I-x.score_G))*1000/\\\n",
    "                         x.taille_content \n",
    "                         for x in df.itertuples()]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR9SbuETaJ5z"
   },
   "source": [
    "Obetenant ainsi un score par article, la fonction d'agrégation utilisée est la moyenne des scores par sites webs.\n",
    "Pour cela on utilise une fonction qui à partir d'un url d'article trouve l'url du site source. Du coup, on se retrouve avec linkedin.com =/= fr.linkedin, mais 2 sites différents avec le même nom (site.fr, www.site.com, etc) sont bien différenciés. Ca nous permet aussi de faire la différence entre la version française et anglaise d'un site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette mesure apporte une meilleure pertinence si elle est utilisée sur le contenu de l'article. Or cette solution fait appel à l'obligation de scrapper les articles pour récupérer le contenu. \n",
    "Or, en suivant les problématiques des scrapeurs (cf documents spécifiques) on se rend compte que le scrapeur générique est nécessaire pour récupérer le contenu des articles. Cette \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1MV02FFUaLhU"
   },
   "outputs": [],
   "source": [
    "def url_site(url_art : str):\n",
    "    \"\"\"Documentation\n",
    "    @Flavien Caminade et Corentin Prat-Marca\n",
    "    Parameters:\n",
    "        url_art : the url of an article\n",
    "    Out :\n",
    "        url_site : the url of a site obtained with the article's url\n",
    "    \"\"\"\n",
    "    site : list  =url_art.split(\"://\")\n",
    "    #keep everything on the right side of \"https://\"\"\n",
    "    if site[0]==\"https\" or site[0]==\"http\":\n",
    "        url_site : str = site[1]\n",
    "    else:\n",
    "        url_site : str = site[0]\n",
    "    #delete everything after the first \"/\"\n",
    "    tab : list = url_site.split(\"/\")\n",
    "    url_site = tab[0]\n",
    "    return url_site\n",
    "\n",
    "def pertinence_4_source(df_pertinence_4 : pd.DataFrame):\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        df_pertinence_4 : a data frame of scrapped articles with their score\n",
    "    Out :\n",
    "        df : a data frame with the score for each sites\n",
    "    \"\"\"\n",
    "    dico : dict ={} #dictionnary : keys=sources url, values=sum of the scores of each articles\n",
    "    for articles in df_calcul_global.itertuples():\n",
    "\n",
    "        if url_site(articles.art_url) in dico: #if the source il already in the dictionnary\n",
    "            dico[url_site(articles.art_url)][0] += (articles.score_total)**2 #using square so higher score have more values\n",
    "            dico[url_site(articles.art_url)][1] += 1 #increasing the number of articles for the source\n",
    "        else :\n",
    "            dico[url_site(articles.art_url)] = [(articles.score_total)**2, 1]\n",
    "\n",
    "    df : pd.DataFrame = pd.DataFrame.from_dict(dico, orient = 'index', columns = ['score_total', 'nb_articles'])\n",
    "    df['score_moyen'] = df.apply(lambda row: row.score_total / row.nb_articles, axis = 1) #mean of the scores of the artciles for each sources\n",
    "    return df\n",
    "#pertinence_4_source(df_pertinence_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8HthiBDaL7v"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4iI0al5XWAz_"
   },
   "outputs": [],
   "source": [
    "def pertinence_6(df : pd.DataFrame): #df avec proba innovation et proba gestion\n",
    "    \"\"\"Documentation\n",
    "    Parameters:\n",
    "        df : a data frame of scrapped articles with the probability for each to contain a \"gestion\" word or an \"innovation\" word (group 5 work)\n",
    "    Out :\n",
    "        df : the same data frame with 4 more columns each containing a score based on the probability\n",
    "    \"\"\"\n",
    "    df['pertinence_10'] = df.apply(lambda row: (10*(row.probaInnovation + row.probaGestion) - abs(row.probaInnovation-row.probaGestion))/20, axis = 1) #(10*(motsGestion+motsInnovation)-abs(motsGestion-motsInnovation)) / 20 (pour un score entre 0 et 1)\n",
    "    df['pertinence_5'] = df.apply(lambda row: (5*(row.probaInnovation + row.probaGestion) - abs(row.probaInnovation-row.probaGestion))/10, axis = 1) #(5*(motsGestion+motsInnovation)-abs(motsGestion-motsInnovation)) / 10 (pour un score entre 0 et 1)\n",
    "    df['pertinence_2'] = df.apply(lambda row: (2*(row.probaInnovation + row.probaGestion) - abs(row.probaInnovation-row.probaGestion))/4, axis = 1) #(2*(motsGestion+motsInnovation)-abs(motsGestion-motsInnovation)) / 4 (pour un score entre 0 et 1)\n",
    "    df['pertinence_F1'] = df.apply(lambda row: 2*(row.probaInnovation * row.probaGestion) / (row.probaInnovation+row.probaGestion), axis = 1) #F1 score adapté\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jop2-2wZWZyb"
   },
   "source": [
    "Cette fonction permet de créer un score de pertinance à partir d'un df d'articles scrappés dont on a les probabilités d'apparitions d'un mot de gestions ou d'innovation (travail du groupe 5).\n",
    "Elle permet d'évaluer les articles pour avoir une idée de la pertinence. Les scores vont de 0 à 1, et prennent en compte la somme des probabilités (plus on a de mots des lexiques, mieux c'est) et la différence des probabilités (les sites avec un nombre à peu près egal de mots de chaques lexiques sont plus intéressants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fnPnsjY7Wbpo"
   },
   "outputs": [],
   "source": [
    "def pertinence_6_source(df_pertinence_6 : pd.DataFrame):\n",
    "    \"\"\"Documentation\n",
    "    Parameters: \n",
    "        df_pertinence_6 : a data frame of scrapped articles with their score, obtained with the function pertinence_6\n",
    "    Out :\n",
    "        df : a data frame of the means of each score for each source\n",
    "    \"\"\"\n",
    "    dico_pertinence : dict = {} #key : a source, values : a list [score_10,score_5,score_2,score_F1,number of articles]\n",
    "    for articles in df_pertinence_6.itertuples():\n",
    "        #if the source arlready is in the dictionnary\n",
    "        if url_site(articles.art_url) in dico_pertinence: \n",
    "            #using square function so that articles with a higher score are more important\n",
    "            dico_pertinence[url_site(articles.art_url)][0] += articles.pertinence_10**2\n",
    "            dico_pertinence[url_site(articles.art_url)][1] += articles.pertinence_5**2\n",
    "            dico_pertinence[url_site(articles.art_url)][2] += articles.pertinence_2**2\n",
    "            dico_pertinence[url_site(articles.art_url)][3] += articles.pertinence_F1**2\n",
    "            #increasing the number or articles\n",
    "            dico_pertinence[url_site(articles.art_url)][4] += 1 \n",
    "        else :\n",
    "            #adding a new source\n",
    "            dico_pertinence[url_site(articles.art_url)]=\n",
    "            [articles.pertinence_10**2,articles.pertinence_5**2,articles.pertinence_2**2,articles.pertinence_F1**2,1]\n",
    "\n",
    "    df : pd.DataFrame = pd.DataFrame.from_dict(dico_pertinence, orient = 'index', columns = ['pertinence_10','pertinence_5','pertinence_2','pertinence_F1', 'nb_articles']) #turning the dictionnary into a data frame\n",
    "    df['pertinence_10_moyenne'] = df.apply(lambda row: row.pertinence_10 / row.nb_articles, axis = 1)\n",
    "    df['pertinence_5_moyenne'] = df.apply(lambda row: row.pertinence_5 / row.nb_articles, axis = 1)\n",
    "    df['pertinence_2_moyenne'] = df.apply(lambda row: row.pertinence_2 / row.nb_articles, axis = 1)\n",
    "    df['pertinence_F1_moyenne'] = df.apply(lambda row: row.pertinence_F1 / row.nb_articles, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M--lIncOZs27"
   },
   "source": [
    "On cherche à obtenir la pertinence des sites, donc on fait la moyenne de la pertinence de chaque articles des sites obtenue avec la fonction précédente. On utilise la fonction carré pour que les articles avec un score faible soient moins importants dans le score total que ceux avec un score élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLeRTUP4oEvU"
   },
   "source": [
    "En résumé, on a 2 manières d'obtenir des scores de pertinence qu'il peut être intéressant de combiner. Par contre elles sont très dépendantes des lexiques et les synonymes ne sont pas forcément pris en compte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4AINGxHol40"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
