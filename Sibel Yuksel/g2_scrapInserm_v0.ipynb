{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Created on Monday Jan 4 14:03:00 \\n2019 Group 2\\n@authors: Sibel Yuksel'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Created on Monday Jan 4 14:03:00 \n",
    "2019 Group 2\n",
    "@authors: Sibel Yuksel\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_extract_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [art_content, art_content_html, art_extract_datetime, art_lang, art_title, art_url, src_name, src_type, src_url, src_img, art_auth, art_tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['art_content','art_content_html','art_extract_datetime','art_lang','art_title','art_url','src_name','src_type','src_url','src_img','art_auth','art_tag']  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_extract_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt; Connaître  l'Inserm &gt; La recherche  à l'Inse...</td>\n",
       "      <td>&lt;p class=\"navPrimary__dropDownTitle\"&gt;&lt;span&gt;&amp;gt...</td>\n",
       "      <td>20.12.2019</td>\n",
       "      <td>fr</td>\n",
       "      <td>Ondes électromagnétiques : Faut-il craindre la...</td>\n",
       "      <td>https://www.inserm.fr/actualites-et-evenements...</td>\n",
       "      <td>Inserm</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>https://www.inserm.fr/</td>\n",
       "      <td>/themes/inserm/inserm_logo_baseline_fr.png</td>\n",
       "      <td>no data</td>\n",
       "      <td>no data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         art_content  \\\n",
       "0  > Connaître  l'Inserm > La recherche  à l'Inse...   \n",
       "\n",
       "                                    art_content_html art_extract_datetime  \\\n",
       "0  <p class=\"navPrimary__dropDownTitle\"><span>&gt...           20.12.2019   \n",
       "\n",
       "  art_lang                                          art_title  \\\n",
       "0       fr  Ondes électromagnétiques : Faut-il craindre la...   \n",
       "\n",
       "                                             art_url src_name      src_type  \\\n",
       "0  https://www.inserm.fr/actualites-et-evenements...   Inserm  xpath_source   \n",
       "\n",
       "                  src_url                                     src_img  \\\n",
       "0  https://www.inserm.fr/  /themes/inserm/inserm_logo_baseline_fr.png   \n",
       "\n",
       "  art_auth  art_tag  \n",
       "0  no data  no data  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.inserm.fr/actualites-et-evenements/actualites/ondes-electromagnetiques-faut-il-craindre-5g'\n",
    "\n",
    "\n",
    "\n",
    "def get_Title(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the title of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_titre = html_soup.title\n",
    "    titre = html_titre.get_text()\n",
    "    return titre\n",
    "    \n",
    "\n",
    "def get_Time(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the time of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_date = html_soup.find('time')\n",
    "    date = html_date.get_text()\n",
    "    return date\n",
    "\n",
    "\n",
    "def get_Img(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the introducing picture of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # pris le logo pour test, pas d'image ici\n",
    "    img = html_soup.find('img', class_='imgResp headerMain__logoBaseline')['src'] \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def get_Tag(url : str) -> str :\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_tag = html_soup.find(\"a\",{'rel':\"category\"})\n",
    "    if html_tag is None:\n",
    "        return None\n",
    "    else:\n",
    "        tag=html_tag.get_text\n",
    "        return tag\n",
    "\n",
    "\n",
    "def get_lang(titre : str) -> str : \n",
    "    \"\"\"\n",
    "    This function analyse the webpage/article language\n",
    "    \"\"\"\n",
    "    a = TextBlob(titre)\n",
    "    langue = a.detect_language()\n",
    "    return langue\n",
    "\n",
    "def art_content_html(titre : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the html content of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    content_html = \" \".join([str(x) for x in paragraphe])\n",
    "    return content_html\n",
    "    \n",
    "def art_content(titre : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the clean content of the webpage/article without \n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    content = \" \".join([x.text for x in paragraphe])\n",
    "    return content\n",
    "\n",
    "def get_Tag(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts different tags of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_tag = html_soup.find(\"a\",{'rel':\"category\"})\n",
    "    if html_tag is None:\n",
    "        return None\n",
    "    else:\n",
    "        tag = html_tag.get_text\n",
    "        return tag\n",
    "    \n",
    "def remplir_dataFrame(url):\n",
    "    \"\"\"\n",
    "    This function add different informations of the webpage/article to the dataFrame\n",
    "    \"\"\"\n",
    "    df.loc[0, 'src_type'] = 'xpath_source'\n",
    "    df.loc[0, 'src_url'] = 'https://www.inserm.fr/'\n",
    "    df.loc[0, 'src_name'] = 'Inserm'\n",
    "    df.loc[0, 'art_auth'] = 'no data'\n",
    "    df.loc[0, 'art_url'] = url\n",
    "    tag = get_Tag(url)\n",
    "    if tag is None or tag==[ ]:\n",
    "        tag = 'no data'\n",
    "    df.loc[0, 'art_tag'] = tag\n",
    "    df.loc[0, 'art_content_html'] = art_content_html(url)\n",
    "    df.loc[0, 'art_content'] = art_content(url)\n",
    "    time = get_Time(url)\n",
    "    if time is None or time==[ ]:\n",
    "        time = 'no data'\n",
    "    df.loc[0, 'art_extract_datetime'] = time\n",
    "    img=get_Img(url)\n",
    "    if img is None:\n",
    "        df.loc[0, 'src_img'] = None\n",
    "    else:\n",
    "        df.loc[0, 'src_img'] = img\n",
    "    titre = get_Title(url)\n",
    "    df.loc[0, 'art_title'] = titre\n",
    "    langue = get_lang(titre)\n",
    "    df.loc[0, 'art_lang'] = langue\n",
    "    return df\n",
    "\n",
    "\n",
    "remplir_dataFrame(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c0296856911f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mart_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_content_html\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_published_datetime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_lang\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_title\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_auth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mart_tag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mscraping_linternaute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c0296856911f>\u001b[0m in \u001b[0;36mscraping_linternaute\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mparagraphe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mart_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparagraphe\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mlangue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titre' is not defined"
     ]
    }
   ],
   "source": [
    "url = 'https://www.inserm.fr/actualites-et-evenements/actualites/ondes-electromagnetiques-faut-il-craindre-5g'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scraping_linternaute(url : 'str') -> list:\n",
    "    \"\"\"Documentation\n",
    "    function which from a url creates a BeautifulSoup object, then extract different informations about the article and the \n",
    "    source. Then researches informations about the article and the website. It finally returns all this data as a list\n",
    "  \n",
    "    Parameters:\n",
    "        url(str): The url that we will scrap \n",
    "        \n",
    "    Out:\n",
    "        list: it contains some propreties of the article and the sources \n",
    "\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    src_type = 'xpath_source'\n",
    "    src_url = 'https://www.inserm.fr/'\n",
    "    src_name = 'Inserm'\n",
    "    art_published_datetime = html_soup.find('time').get_text()\n",
    "    art_title = html_soup.title.get_text()\n",
    "    # pris le logo pour test, pas d'image ici\n",
    "    img = html_soup.find('img', class_='imgResp headerMain__logoBaseline')['src']\n",
    "    \n",
    "    html_tag = html_soup.find(\"a\",{'rel':\"category\"})\n",
    "    if html_tag is None:\n",
    "        tag = 'no-data'\n",
    "    else:\n",
    "        tag = html_tag.get_text()\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    art_content_html = \" \".join([str(x) for x in paragraphe])\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    art_content = \" \".join([x.text for x in paragraphe])\n",
    "    a = TextBlob(titre)\n",
    "    langue = a.detect_language()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return [art_content,art_content_html,art_published_datetime,art_lang,art_title,art_url,src_name,src_type,src_url,art_img,art_auth,art_tag] \n",
    "\n",
    "scraping_linternaute(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
