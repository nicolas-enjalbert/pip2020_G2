{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Created on Monday Jan 5 14:03:00 \\n2019 Group 2\\n@authors: Sibel Yuksel'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Created on Monday Jan 5 14:03:00 \n",
    "2019 Group 2\n",
    "@authors: Sibel Yuksel, Marianne Manson (v1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\y-sib\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_extract_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [art_content, art_content_html, art_extract_datetime, art_lang, art_title, art_url, src_name, src_type, src_url, src_img, art_auth, art_tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['art_content','art_content_html','art_extract_datetime','art_lang','art_title','art_url','src_name','src_type','src_url','src_img','art_auth','art_tag']  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_extract_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La bonne connaissance des besoins de l’entrepr...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;La bonne connaissance des besoins d...</td>\n",
       "      <td>26 Mai 2020</td>\n",
       "      <td>fr</td>\n",
       "      <td>Les raisons d'utiliser l’intelligence artifici...</td>\n",
       "      <td>https://www.parlonsrh.com/raisons-utiliser-lin...</td>\n",
       "      <td>parlonsrh</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>https://www.parlonsrh.com/</td>\n",
       "      <td>https://www.parlonsrh.com/wp-content/uploads/2...</td>\n",
       "      <td>Baptiste Julien Blandet</td>\n",
       "      <td>[Big data, Compétences, Transformation rh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         art_content  \\\n",
       "0  La bonne connaissance des besoins de l’entrepr...   \n",
       "\n",
       "                                    art_content_html art_extract_datetime  \\\n",
       "0  <p><strong>La bonne connaissance des besoins d...          26 Mai 2020   \n",
       "\n",
       "  art_lang                                          art_title  \\\n",
       "0       fr  Les raisons d'utiliser l’intelligence artifici...   \n",
       "\n",
       "                                             art_url   src_name      src_type  \\\n",
       "0  https://www.parlonsrh.com/raisons-utiliser-lin...  parlonsrh  xpath_source   \n",
       "\n",
       "                      src_url  \\\n",
       "0  https://www.parlonsrh.com/   \n",
       "\n",
       "                                             src_img                 art_auth  \\\n",
       "0  https://www.parlonsrh.com/wp-content/uploads/2...  Baptiste Julien Blandet   \n",
       "\n",
       "                                      art_tag  \n",
       "0  [Big data, Compétences, Transformation rh]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.parlonsrh.com/raisons-utiliser-lintelligence-artificielle-dans-gestion-gpec/'\n",
    "url2 = \"https://www.parlonsrh.com/actus/2020-une-annee-pas-comme-les-autres/\"\n",
    "\n",
    "\n",
    "def get_Title(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the title of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_titre = html_soup.title\n",
    "    titre = html_titre.get_text()\n",
    "    return titre\n",
    "    \n",
    "def get_Time(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the time of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    date = html_soup.find(\"span\", {\"class\":\"date updated value-title\"})[\"title\"]\n",
    "    return date\n",
    "\n",
    "def get_lang(titre : str) -> str : \n",
    "    \"\"\"\n",
    "    This function analyse the webpage/article language\n",
    "    \"\"\"\n",
    "    a = TextBlob(titre)\n",
    "    langue = a.detect_language()\n",
    "    return langue\n",
    "\n",
    "def get_Img(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the introducing picture of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    img = html_soup.find('meta', {'property':'og:image'})['content'] \n",
    "    return img\n",
    "\n",
    "\n",
    "def art_content_html(titre : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the html content of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    content_html = \" \".join([str(x) for x in paragraphe])\n",
    "    return content_html\n",
    "    \n",
    "def art_content(titre : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the clean content of the webpage/article without \n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    content = \" \".join([x.text for x in paragraphe])\n",
    "    return content\n",
    "\n",
    "def get_Tag(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts different tags of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html_tag = html_soup.find_all(\"meta\",{'property':\"article:tag\"})\n",
    "    Tags = []\n",
    "    for i in html_tag:\n",
    "        tag_i = i['content']\n",
    "        Tags.append(tag_i)\n",
    "    return Tags\n",
    "\n",
    "def get_Author(url : str) -> str :\n",
    "    \"\"\"\n",
    "    This function extracts the name of the author of the webpage/article\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    author = html_soup.find(\"span\",{\"class\":\"fn\"}).get_text()\n",
    "    if author[11:29]=='La Team Parlons RH':\n",
    "        return author[11:29] \n",
    "    else:\n",
    "        return author[11:34]\n",
    "\n",
    "def remplir_dataFrame(url):\n",
    "    \"\"\"\n",
    "    This function add different information of the webpage/article to the dataFrame\n",
    "    \"\"\"\n",
    "    df.loc[0, 'src_type'] = 'xpath_source'\n",
    "    df.loc[0, 'src_url'] = 'https://www.parlonsrh.com/'\n",
    "    df.loc[0, 'src_name'] = 'parlonsrh'\n",
    "    df.loc[0, 'art_url'] = url\n",
    "    \n",
    "    df.loc[0, 'art_auth'] = get_Author(url)\n",
    "    tag = get_Tag(url)\n",
    "    if tag is None or tag==[ ]:\n",
    "        tag = 'no data'\n",
    "    df.loc[0, 'art_tag'] = tag\n",
    "    df.loc[0, 'art_content_html'] = art_content_html(url)\n",
    "    df.loc[0, 'art_content'] = art_content(url)\n",
    "    time = get_Time(url)\n",
    "    if time is None or time==[ ]:\n",
    "        time = 'no data'\n",
    "    df.loc[0, 'art_extract_datetime'] = time\n",
    "    img=get_Img(url)\n",
    "    if img is None:\n",
    "        df.loc[0, 'src_img'] = 'no data'\n",
    "    else:\n",
    "        df.loc[0, 'src_img'] = img\n",
    "    titre = get_Title(url)\n",
    "    df.loc[0, 'art_title'] = titre\n",
    "    langue = get_lang(titre)\n",
    "    df.loc[0, 'art_lang'] = langue\n",
    "    return df\n",
    "\n",
    "\n",
    "remplir_dataFrame(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url : 'https://www.parlonsrh.com/raisons-utiliser-lintelligence-artificielle-dans-gestion-gpec/'\n",
    "def scraping(url):\n",
    "    response = requests.get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #content\n",
    "    paragraphe = html_soup.find_all('p')\n",
    "    content = \" \".join([x.text for x in paragraphe])\n",
    "    #content_html\n",
    "    content_html = \" \".join([str(x) for x in paragraphe])\n",
    "    #time\n",
    "    time = html_soup.find(\"span\", {\"class\":\"date updated value-title\"})[\"title\"]\n",
    "    if time is None or time==[ ]:\n",
    "        time = 'no data'\n",
    "    else:\n",
    "        trans_month = {'01':['janvier'], \n",
    "             '02':['février'],\n",
    "             '03':['mars'],\n",
    "             '04':['avril'],\n",
    "             '05':['mai'],\n",
    "             '06':['juin'],\n",
    "             '07':['juillet'],\n",
    "             '08':['août'],\n",
    "             '09':['septembre'],\n",
    "             '10':['octobre'],\n",
    "             '11':['novembre'],\n",
    "             '12':['décembre']}\n",
    "        date_tab = time.split(\" \")\n",
    "        day = date_tab[0]\n",
    "        month = date_tab[1]\n",
    "        for m in trans_month:\n",
    "            if month.lower() in trans_month[m]:\n",
    "                month = m\n",
    "        year = date_tab[2]\n",
    "        time = datetime.datetime(int(year), int(month), int(day))\n",
    "    #title\n",
    "    html_title = html_soup.title\n",
    "    title = html_title.get_text()\n",
    "    #img\n",
    "    img = html_soup.find('meta', {'property':'og:image'})['content']\n",
    "    if img is None:\n",
    "        img = 'no_data'\n",
    "    #author\n",
    "    author = html_soup.find(\"span\",{\"class\":\"fn\"}).get_text()\n",
    "    if author[11:29]=='La Team Parlons RH':\n",
    "        author = author[11:29] \n",
    "    else:\n",
    "        author = author[11:34]\n",
    "    #tag\n",
    "    html_tag = html_soup.find_all(\"meta\",{'property':\"article:tag\"})\n",
    "    tags = []\n",
    "    for i in html_tag:\n",
    "        tag_i = i['content']\n",
    "        tags.append(tag_i)\n",
    "    if tags is None or tags==[ ]:\n",
    "        tags = 'no data'\n",
    "    new_row = {'art_content': content ,\n",
    "               'art_content_html': content_html ,\n",
    "               'art_published_datetime': time ,\n",
    "               'art_lang': 'fr' , \n",
    "               'art_title' : title , \n",
    "               'art_url' : url ,\n",
    "               'src_name' : 'parlonsrh' ,\n",
    "               'src_type' : 'xpath_source' ,\n",
    "               'src_url' : 'https://www.parlonsrh.com/' ,\n",
    "               'src_img' : img ,\n",
    "               'art_auth': author,\n",
    "               'art_tag': tags}\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_content</th>\n",
       "      <th>art_content_html</th>\n",
       "      <th>art_published_datetime</th>\n",
       "      <th>art_lang</th>\n",
       "      <th>art_title</th>\n",
       "      <th>art_url</th>\n",
       "      <th>src_name</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_url</th>\n",
       "      <th>src_img</th>\n",
       "      <th>art_auth</th>\n",
       "      <th>art_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La bonne connaissance des besoins de l’entrepr...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;La bonne connaissance des besoins d...</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>fr</td>\n",
       "      <td>Les raisons d'utiliser l’intelligence artifici...</td>\n",
       "      <td>https://www.parlonsrh.com/raisons-utiliser-lin...</td>\n",
       "      <td>parlonsrh</td>\n",
       "      <td>xpath_source</td>\n",
       "      <td>https://www.parlonsrh.com/</td>\n",
       "      <td>https://www.parlonsrh.com/wp-content/uploads/2...</td>\n",
       "      <td>Baptiste Julien Blandet</td>\n",
       "      <td>[Big data, Compétences, Transformation rh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         art_content  \\\n",
       "0  La bonne connaissance des besoins de l’entrepr...   \n",
       "\n",
       "                                    art_content_html art_published_datetime  \\\n",
       "0  <p><strong>La bonne connaissance des besoins d...             2020-05-26   \n",
       "\n",
       "  art_lang                                          art_title  \\\n",
       "0       fr  Les raisons d'utiliser l’intelligence artifici...   \n",
       "\n",
       "                                             art_url   src_name      src_type  \\\n",
       "0  https://www.parlonsrh.com/raisons-utiliser-lin...  parlonsrh  xpath_source   \n",
       "\n",
       "                      src_url  \\\n",
       "0  https://www.parlonsrh.com/   \n",
       "\n",
       "                                             src_img                 art_auth  \\\n",
       "0  https://www.parlonsrh.com/wp-content/uploads/2...  Baptiste Julien Blandet   \n",
       "\n",
       "                                      art_tag  \n",
       "0  [Big data, Compétences, Transformation rh]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "df = pd.DataFrame(columns=['art_content','art_content_html','art_published_datetime','art_lang','art_title','art_url','src_name','src_type','src_url','src_img','art_auth','art_tag'])\n",
    "new_row = scraping('https://www.parlonsrh.com/raisons-utiliser-lintelligence-artificielle-dans-gestion-gpec/')\n",
    "df_test = df.append(new_row, ignore_index=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
